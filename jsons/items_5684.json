[{"detail": [{"content": "Privacy Research Group | NYU School of Law                          Skip to main content                                     &rsaquo;               Quicklinks       Areas of Study   Calendar   Career Services   Colloquia   Courses   Departments   Directories   Docket   Housing   Library   News and Press   NYU Home   Student Links   Technology                                              JD Admissions   Faculty &amp; Scholarship   Global Opportunities   LLM/JSD Admissions   Academics &amp; Courses   Law &amp; Business   Executive Education   Current Students   Public Service   About NYU Law   Alumni &amp; Giving   Centers &amp; Institutes                               Home &rsaquo; Centers &amp; Institutes &rsaquo; Information Law Institute &rsaquo; Privacy Research Group             Privacy Research Group                 Information Law Institute       Events   People   Research   Privacy Research Group   Security Seminar   ILI Student Blog   Contact Us                               \u2028   The Privacy Research Group is a weekly meeting of students, professors, and industry professionals who are passionate about exploring, protecting, and understanding privacy in the digital age.     Joining PRG:   Because we deal with early-stage work in progress, attendance at meetings of the Privacy Research Group is generally limited to researchers and students who can commit to ongoing participation in the group. To discuss joining the group, please contact Professor Helen Nissenbaum or Professor Katherine Strandburg. If you are interested in these topics, but cannot commit to ongoing participation in PRG, you may wish to join the PRG-All mailing list.     PRG Calendar   Spring 2015   April 29: Cases, Controversies, Technologies\u2028   April 22: Helen Nissenbaum - Respect for Context' as a Benchmark for Privacy: What it is and Isn't   April 15: Joris van Hoboken - From Collection to Use Regulation? A Comparative Perspective   ABSTRACT: In the debates about data privacy for the 21st century, we increasingly hear the argument hat regulation should focus on the use of data instead of its initial collection. The argument for this shift tends to be pragmatic: the collection of personal data has become the normal state of affairs to such an extent that focusing the regulation of personal data driven processes through limiting the collection of data (input) is no longer feasible and desirable. Instead, regulation should focus on issues related to the actual use (output). This paper will look at this position from a comparative perspective. It will first explore the different positions that have been expressed in the relevant literature, look at the position of data (collection) minimization and purpose limitation in the US and European regulatory systems and analyze them in comparative perspective, focusing on the different rationales underlying the regulation of \u2018collection\u2019 on the one hand, and \u2018use\u2019 on the other hand.   April 8: Bilyana Petkova\u2028 - Privacy and Federated Law-Making in the EU and the US: Defying the Status Quo?   ABSTRACT: The federated nature of lawmaking in both the United States and the European Union is seen to deliver sub-optimal results. In particular, in the US there are concerns for the increased fragmentation of American data privacy law and the lack of relevant federal consolidation, whereas in the EU the proposed General Data Protection Regulation and overall data protection regime generated opposition regarding the over-centralization of powers to the European institutions. My argument is that the autonomy of state institutions and regulatory experimentation on the state level can defy the status quo, be that of too little or too much privacy consolidation. I look into the role of Member States\u2019 parliaments and highest courts in the EU and of state attorneys general in the US. Arguably, regulatory experimentation with higher data privacy standards in individual states like Germany or California has the potential of generating a dynamic of horizontal adaptation among jurisdictions and industry players that the federal or EU tier can capitalize on to level up privacy protection.   April 1: Paula Kift \u2014 Metadata: An Ontological and Normative Analysis\u2028   ABSTRACT: When the legality of the bulk telephony metadata program was challenged, the NSA countered that it was not collecting the content but only the metadata of communications. The aim of this paper is to discover where the distinction between metadata and content data came from and whether this distinction still makes sense today. The first part of the paper relies on Klayman v. Obama and ACLU v. Clapper to look at the various dichotomies the courts have used to define metadata over time: content vs. non-content information, sensitive vs. non-sensitive information and private records vs. business records held by third parties. The second part of the paper engages in a normative analysis of the bulk telephony metadata program based on the framework of contextual integrity. The paper finds that the bulk telephony metadata program violates entrenched informational norms.\u2028   March 25: Alex Lipton \u2014 Privacy Protections for the Secondary User of Consumer-Watching Technologies\u2028   ABSTRACT: Consumer products increasingly record user data without regard to whether the recorded individual is the primary user\u2014the purchaser of the product\u2014or the secondary user\u2014an individual who uses the product but is not the purchaser. This distinction proves especially significant when considering the product's privacy policy, which purports to establish user consent to expansive data use practices, and statutory protections governing the recording of user data, many of which include exceptions based on user consent. This Note examines one private regime for protecting consumer privacy\u2014privacy policies\u2014and several public regimes\u2014including state wiretap laws, the Electronic Communications Privacy Act, and the Children's Online Privacy Protection Act\u2014to illustrate how legal protections differ for primary and secondary users of consumer-watching technologies. I conclude by suggesting a framework for designing privacy protections for the secondary user of consumer-watching technologies.\u2028   March 11: Rebecca Weinstein (Cancelled\u2028)   March 4: Karen Levy &amp; Alice Marwick \u2014 Unequal Harms: Socioeconomic Status, Race, and Gender in Privacy Research\u2028   ABSTRACT: (NOTE: this is a nascent idea and we're envisioning PRG as primarily a time for discussion of these issues, rather than a research presentation. We'll do a short presentation and then open it up to the group.) While privacy and surveillance affect different populations in disparate ways (Gilman 2012), they are often treated as a monolithic concept by privacy researchers. Show more/less  While researchers in disciplines like women\u2019s studies, sociology, and criminology have examined the impact of the welfare system (Eubanks 2006), the criminal justice system (Goffman 2014), and differential access to technology on privacy (Vickery 2014), these issues may not be labeled or easily recognized as privacy-related by the mainstream of privacy scholarship. Examining the major academic privacy conferences and scholarship of the last few years leads to the conclusion that the normative subject of much privacy research is middle-class, white, and male. However, it is the researchers, think-tank directors, advocates and activists attending these conferences whose work often informs public policy. By incorporating research that is often left out by privacy scholars, and by advocating for projects that discuss more diverse conceptualizations of \u201cthe user\u201d or the subject, we can envision a future for privacy policy that incorporates a wider set of harms and needs, and encompasses the concerns of a larger base of citizens.     \u2028February 25 : Luke Stark \u2014 NannyScam: The Normalization of Consumer-as-Surveillorm\u2028   ABSTRACT: With the proliferation of surveillance technologies in the developed world over the past decade, norms of surveillance are appearing in novel forms and new ways across the terrain of everyday life. While there has been much academic scrutiny of certain aspects of this trend, such as surveillance in the workplace, the collection and analysis of consumer data through loyalty cards and other mechanisms, and location tracking through mobile digital devices, this paper explores an under-studied facet of quotidian surveillance: the construction of a new subject position, that of the consumer not just as surveilled but as also as surveillor. Show more/less The technologies and practices that are acting together to constitute this subject position are not new in themselves _ these include the by-now familiar processes of online self-service, by which consumers are asked to navigate and analyze algorithmic systems in search for their desired product; consumer-grade surveillance products, which have progressed from nanny-cams and baby monitors to the much maligned Elf on the Shelf toy; and most recent and perhaps most troubling, systems of public facing service-sector surveillance (such as Domino\u2019s Pizza\u2019s online order tracker) that give consumers oversight over service-sector workers without control or autonomy on either side. I argue that the confluence of these three sets of technical and social infrastructures places consumers midway within in a hierarchy of everyday surveillance, recreating familiar inequalities of power, access and influence in the process. These systems require not only a material infrastructure for the normalization of surveillance, but also an ideological and emotional one. I suggest that making consumers responsible for the surveillance not only of their own affairs but also the work of others classified as subordinate to them (such as children, service workers, and members of other disenfranchised groups) positions the figure of the consumer as the emotional manager of the experience of surveillance, and reifies a broader material trend within late capitalism: the equation of financial wealth with moral weight in a hierarchy of oversight that gives the wealthiest the most control and least accountability. Implicated within a chain of surveillance that has colonial echoes, the play of everyday social relations have thus become integrated into the broader networks of digital surveillance overseen by governments and corporate actors. In the paper, I will lay out a taxonomy of both historical and contemporary consumer surveillance products and services that supports my analysis above. I will explore how two trends _ infantilization and expectations around parental power and responsibility, and the history of workplace surveillance _ have become models for the transference of surveillance norms to consumers. Based on these models, I will examine possible legal and policy remedies for the political and social challenges posed by the normalization of the consumer-as-surveillor. These include wellknown problems around a lack of what Cohen terms \u201csemantic discontinuities within daily life, leading to the diminution of creativity, agency and human flourishing; concerns also include the normalization of the emotional toll not simply of state surveillance, but also surveillance by one\u2019s fellow citizens in ways reminiscent of the living conditions within totalitarian states.     \u2028February 18: Brian Choi // A Prospect Theory of Privacy\u2028   ABSTRACT: Privacy law differs from other information law doctrines in that it is guided almost exclusively by moral intuition. What qualifies as a \u201cviolation\u201d of privacy turns in large part on the moral reprehensibility of the act in question. By stark contrast, the intellectual property regimes are led primarily by economic considerations, and only secondarily by non-economic factors.  Show more/less Likewise, free speech doctrine is dominated by the value-agnostic \u201cmarketplace of ideas.\u201d In other words, the major disconnect between intellectual \u201cprivacy\u201d and intellectual \u201cproperty\u201d has been the relative priority assigned to the individual\u2019s right to control versus the social cost-benefit of proscribing access by others. Yet, if data is a commodity of value, then the cultivation of such data is a social good, not just an individual entitlement. Where moral rhetoric has failed to advance robust recognition of privacy interests, utilitarian frameworks may prove more effective. In particular, prospect theory offers several useful insights. First, prospect theory posits that individuals should be allowed to rely on more than secrecy to guard informational resources. Presently, because recognition of privacy claims is weak, the production of private data depends heavily on secrecy. Thus, people will either invest in increasingly costly secrecy measures or opt out of the data economy entirely. Both lead to immense social waste. Second, prospect theory suggests that the assignment of informational rights encourages the sharing of information, thus reducing duplicative efforts to generate data. In the patent regime, the goal is commercialization of invention to promote the useful arts. In the privacy regime, the goal is the advancement of social progress through the collective pooling of private experience\u2014which would otherwise remain stashed away. By viewing private data as a valuable commodity to be cultivated, rather than as an inevitable outgrowth of human interaction, we can lend fresh perspective as to what privacy is for.   \u2028   February 11: Aimee Thomson \u2014 Cellular Dragnet: Active Cell Site Simulators and the Fourth Amendment\u2028   ABSTRACT: This Paper examines government use of active cell site simulators (ACSSs) and concludes that ACSS operations constitute a Fourth Amendment search. An ACSS known colloquially as a stingray, triggerfish, or dirtbox mimics a cell phone tower, forcing nearby cell phones to register with the device and divulge identifying and location information. Show more/less  Law enforcement officials regularly use ACSSs to identify and locate individuals, often with extreme precision, while sweeping up the identifying and location information of hundreds or thousands of third parties in the process. Despite the pervasive use of ACSSs at federal, state, and local levels, law enforcement duplicity concerning ACSS operations has prevented courts from closely examining their constitutionality. ACSS operations constitute a Fourth Amendment search under both the trespass paradigm and theprivacy paradigm. Within the former, an ACSS emits radio signals that trespass on private \"effects.\" Under the Jones reinvigoration of the trespass paradigm, radio signals \"touch\" cell phones for the purpose of obtaining information, constituting a Fourth Amendment trespass. Radio signals also trespass under common law property and tort regimes, and the Paper proposes a new rule, consistent with existing trespass jurisprudence, to target only those radio signals that intentionally and without consent cause an active physical change in the cell phone. Within the latter, ACSS operations constitute a Fourth Amendment search because they violate users' subjective expectations of privacy that society can and should recognize as reasonable, particularly if Fourth Amendment jurisprudence continues to eliminate secrecy as a proxy for privacy. Until courts decisively recognize warrantless ACSS operations as illegal, however, advocates and litigants can implement several interim remedial measures. An ACSS is an undeniably valuable law enforcement tool. Subjecting ACSS operations to Fourth Amendment strictures will not hinder their utility but rather ensure that this powerfully invasive technology is not abused.   \u2028   February 4: Ira Rubinstein \u2014 Anonymity and Risk\u2028   ABSTRACT: The possibility of re-identifying anonymized data sets has sparked one of the most lively and important debates in privacy law. The credibility of anonymization, which anchors much of privacy law, is now open to attack. Critics of anonymization argue that almost any data set is vulnerable to a re-identification attack given the inevitability of related data becoming publicly available over time.  Show more/less  Defenders of anonymization counter that despite the theoretical and demonstrated ability to mount such attacks, the likelihood of re-identification for most data sets remains minimal. As a practical matter, they argue, most data sets will remain anonymized using established techniques. Both sides of this debate are now entrenched in their positions, making increasingly technical arguments that are siloed from other relevant aspects of privacy law. As a result, a consensus is elusive. This article aims to help resolve this impasse between formalists (for whom mathematical proof is the touchstone of any meaningful policy) and pragmatists (for whom workable solutions always prevail over theoretical concerns) by reframing the debate away from the endpoint of anonymity and toward the process of risk management. In order to develop a clear, flexible, and workable legal framework for de-identification, we propose drawing from the related, more established area of data security. The law of data security is focused on mandating processes that decrease the likelihood of harm, even if threats are remote. Because there is no such thing as perfect protection, data security policy is decidedly focused on protocols, organizational structure, and the implementation of safeguards. Data security policy also largely refrains from overly-specific rules, deferring instead to a reasonable adherence to industry standards. As the motivation for a consistent approach to de-identify data increases, industry standards will inevitably develop in coordination with public policy and consumer protection goals. A reasonableness approach is also capable of incorporating both legal and technical solutions to the re-identification problem where appropriate. An effective strategy would be to combine contractual prohibitions prohibiting re-identification with scientific approaches to de-identification such as differential privacy and k-anonymity. In short, the law of de-identification should look more like the law of data security: process-based, contextual, and tolerant of risk. Our proposal also argues against a full embrace of the pragmatism and status quo advocated by defenders of anonymization. To begin with, the way this issue is framed is a problem. We join the critics in arguing that the terms \u201canonymous\u201d and \u201canonymization\u201d should be abandoned in our policy and discourse. Almost all uses of the term to describe data sets are misleading if not deceptive. Focusing on the language of risk will better set expectations. Additionally, anonymization critics have rightfully pointed out it is a mistake to overly rely upon risk assessments that cannot account for new data inputs and increasingly sophisticated analytical techniques. An effective risk-based approach to de-identification should accommodate risk models as well as important baseline protections for consumers. In this article, we aim to move past the criticism and defense of anonymization to propose a policy-driven and comprehensive risk-based de-identification framework. Risk-based de-identification should do at least four things: 1) Cover all foreseeably personal data; 2) Tether degree of obligation and punishment to risk; 3) Embrace the full scope of potential harms and available remedies; and, perhaps most controversially, 4) Minimize or eliminate \u201crelease and forget\u201d data sets. Risk-based de-identification is capable of bridging the gap between the formalists and the pragmatists. The approach recognizes that there is no perfect anonymity. Its focus is on process rather than endpoints. Yet effective risk-based de-identification also avoids a ruthless pragmatism by acknowledging the limits of current risk projection models and building in important protections for individual privacy. This policy-driven, integrated, and comprehensive approach will help us advance this important debate into the next stage of implementation.   \u2028   January 28: Scott Skinner-Thomson \u2014 Outing Privacy\u2028   ABSTRACT:The government regularly outs information concerning people\u2019s sexuality, gender identity, and HIV-status. Notwithstanding the implications of such outings, the Supreme Court has yet to answer whether the Constitution contains a right to informational privacy\u2014a right to limit the government\u2019s ability to collect and disseminate personal information.  Show more/less In fact, the Court has on three occasions reluctantly \u201cassumed\u201d that there is such a right without authoritatively recognizing the right or defining its contours. This Article probes informational privacy theory and jurisprudence in order to better understand why the judiciary has been reluctant to fully embrace a robust constitutional right to informational privacy. In short, the Article argues that while existing theories of informational privacy beneficially encourage us to broadly imagine the right and its possibilities, often focusing on informational privacy\u2019s ability to promote individual dignity and autonomy, there is often a disconnect when courts attempt to translate current theories into workable doctrine. The Article reorients and hones the focus of the purported right to informational privacy toward what the Due Process Clause suggests as the right\u2019s two principal and more concrete values: preventing intimate, personal information from serving as the basis for potential discrimination and creating space for the formation of political thought. By so doing, not only is a more precise theory of informational privacy constructed, but, instrumentally (and perhaps most importantly), courts will be more apt to recognize a constitutional informational privacy right and individuals will be better insulated from discrimination or marginalization on the basis of their intimate information or political beliefs.       Fall 2014   December 3: Katherine Strandburg \u2014 Discussion of Privacy News [which can include recent court decisions, new technologies or significant industry practices]\u2028   November 19: Alice Marwick \u2014 Scandal or Sex Crime? Ethical and Privacy Implications of the Celebrity Nude Photo Leaks\u2028   November 12: Elana Zeide \u2014 Student Data and Educational Ideals: examining the current student privacy landscape and how emerging information practice and reforms implicate long-standing social and legal traditions surrounding education in America. The Proverbial Permanent Record [PDF]\u2028   November 5: Seda Guerses \u2014 Let's first get things done! On division of labor and practices of delegation in times of mediated politics and politicized technologies   \u2028ABSTRACT: During particular historical junctures, characterized by crisis, deepening exploitation and popular revolt, referred to here as \u201csneaky moments\u201d, hegemonic hierarchies are simultaneously challenged and reinvented, and in case of the latter in due course subtly reproduced. The current divide between those engaged in politics of technology and those participating in struggles of social justice requires reflection in this context.  Show more/less  We argue that especially the delegation of technological matters to the experienced \"techies\" or \"technological platforms\", and the corresponding flattening of politics and all political activities in the process of developing technical tools and platforms, exacerbate this problem. These tangible divergences in daily practice, however, are not only due to philosophical or political differences. They are also related to the ways in which specialization of work and scarcity of resources leads to a division of labor that often expresses itself across existing fault-lines of race, gender, class and age. Assuming that these moments in which collectives fall back on hegemonic divisions of labor are part and parcel of the divergence between technology politics and social justice politics, we want to ask: are these divisions of labor inevitable? In this paper that is still in progress, we specifically look at the rise of consciousness about surveillance programs post-MENA uprisings as well as Snowden revelations, and the way the counter-surveillance technology campaigns that ensued reconfigured the division of labor between social justice and tech freedom activists. Given the urgency of the moment as well as the momentum created in response to the revelations and news about government surveillance programs, numerous digital rights and freedoms organizations joined campaigns to promote encryption toolkits that \"enhance privacy\" and \"reset the net\" for \"users around the globe\". Through a close reading of these campaign websites, their forms of narration, vocabulary, design decisions, as well as their editorial and technical decisions, we explore how work has been divided between 'techies' and 'activists' and consider ways in which things could have been different.   \u2028   October 29:   Luke Stark \u2014 Discussion on whether \u201cnotice\u201d can continue to play a viable role in protecting privacy in mediated communications and transactions given the increasing complexity of the data ecology and economy.   Kristen Martin \u2014 Transaction costs, privacy, and trust: The laudable goals and ultimate failure of notice and choice to respect privacy online\u2028 Ryan Calo \u2014 Against Notice Skepticism in Privacy (and Elsewhere)\u2028 Lorrie Faith Cranor \u2014 Necessary but Not Sufficient: Standardized Mechanisms for Privacy Notice and Choice.\u2028 October 22: Matthew Callahan \u2014 Warrant Canaries and Law Enforcement Responses. \u2028As background, he recommends reading, \"Twitter's First Amendment Suit &amp; the Warrant Canary Question\" by Brett Max Kaufman in the Just Security blog.\u2028 October 15: Karen Levy \u2014 Networked Resistance to Electronic Surveillance. \u2028October 8: Joris van Hoboken \u2014 The Right to be Forgotten Judgement in Europe: Taking Stock and Looking Ahead\u2028 October 1: Giancarlo Lee \u2014 Automatic Anonymization of Medical Documents.\u2028 September 24: Christopher Sprigman \u2014 MSFT \"Extraterritorial Warrants\" Issue \u2028September 17: Sebastian Zimmeck \u2014 Privee: An Architecture for Automatically Analyzing Web Privacy Policies [with Steven M. Bellovin].\u2028 September 10: Organizational meeting.     Spring 2014   April 30: Seda Guerses \u2014 \"Privacy is Security is a prerequisite for Privacy is not Security is a delegation relationship\"\u2028   ABSTRACT: Since the end of the 60s, computer scientists have engaged in research on privacy and information systems. Over the years, this research has led to a whole palette of \u201cprivacy solutions.\u201d These solutions originate from diverse sub-fields of computer science, e.g., security engineering, databases, software engineering, HCI, and artificial intelligence.  Show more/less From a bird\u2019s eye view, all of these researchers are studying privacy. However, a closer look reveals that each community of researchers relies on different, sometimes even conflicting, definitions of privacy, and on a variety of social and technical assumptions. For example, a good number of privacy researchers define privacy in terms of a known \"security property\": confidentiality. Others contest this approach and suggest that the binary understanding of privacy as concealment and violation of privacy as exposure is too simplistic and at times misleading. During my talk, I will lay out some of the elements of this particular contestation. I will do so by presenting the way in which the interplay between privacy and security is articulated by some of the researchers who participated in an empirical study of privacy research within computer science. This will be a follow up of my PRG presentation in the Fall of 2013, where I presented some of the privacy definitions and conflicting assumptions as they were articulated by differential privacy researchers, data analysts and security engineers.   \u2028   April 23: Milbank Tweed Forum Speaker \u2014 Brad Smith: \"The Future of Privacy\".\u2028   April 16: Solon Barocas \u2014 \"How Data Mining Discriminates\" - a collaborative project with Andrew Selbst, 2012-13 ILI Fellow   \u2028ABSTRACT: This presentation considers recent computer science scholarship on non-discriminatory data mining that has demonstrated\u2014unwittingly, in some cases\u2014the inherent limits of the notion of procedural fairness that grounds anti-discrimination law and the impossibility of avoiding a normative position on the fairness of specific outcomes.\u2028April 9: Florencia Marotta-Wurgler \u2014 \"The Anatomy of Privacy\" - initial findings from her empirical study on privacy policies\u2028April 2: Elana Zeide\u2014 \"Student Privacy in Context: Intuition, Ignorance and Trust\"\u2028March 26: Heather Patterson \u2014 \"When Health Information Goes Rogue: Privacy and Ethical Implications of Decentextualized Information Flows from Consumer Mobile Fitness Devices to Clinician, Insurers, and Employers\"\u2028ABSTRACT: The rapid proliferation of health apps, digital sensors, and other participatory personal data collection devices points to an increasingly personalized future of health care, whereby individuals will track their own physiological and behavioral biomarkers in near real time and receive tailored feedback from an expanding team of commercial entities, social networks, and clinical care providers.  Show more/less Although much of the data processed by commercial sensors and apps is closely aligned with\u2014and sometimes identical to\u2014traditional health care data, its privacy and security are generally not subject to federal or state health privacy regulations by virtue of being held by non-HIPAA covered entities. Worryingly, the collection, integration, analysis, and distribution of this commercially tracked health data may expose individuals to the very privacy and security consequences that health privacy laws were developed to prevent, potentially disrupting the values of the health care system itself. This Article discusses technological, regulatory, and social drivers of digital health technology, reviews privacy harms associated with mobile self-tracking devices\u2014focusing particularly on unconstrained and decontextualized information flows mediated by commercial \u201chealth data intermediaries\u201d\u2014and argues that the likely absorption of sensor data into the traditional medial ecosystem will present challenges to consumer privacy that current regulations are insufficient to address. It proposes that modern health privacy regimes ought to more fully take into account new data flow practices presented by emerging health technologies, both by affirmatively granting health technology users the right to exercise granular and contextual controls over their own health data, and by adopting by default an anti-discrimination framework preventing employers and insurers from penalizing individuals for health inferences made about them from sensors and other \u201cInternet of Things\u201d technologies.     March 12: Scott Bulua &amp; Amanda Levendowski \u2014 Challenges in Combatting Revenge Porn\u2028   ABSTRACT: Revenge porn - sexually explicit images that are publicly shared online, without the consent of the pictured individual - has become the a hot button issue for journalists and academics, lawyers and activists.  Show more/less  The phenomenon is surprisingly common: According to a McAfee survey, one in ten former partners threaten to post sexually explicit images of their exes online. An estimated 60 percent follow through. The harms caused by revenge porn can be very real - people featured on these sites often receive solicitations over social media, lose their jobs, or live in fear that their families and future employers will discover the photos. We will examine the challenges of combatting revenge porn: websites hosting this kind of content are afforded broad immunity under the Communications Decency Act Section 230; existing stalking and harassment laws rarely apply to the conduct of revenge porn submitters and websites; few privacy torts encompass the behaviors of revenge porn submitters; proposed legislation often runs afoul of the First Amendment. Our discussion will center on why the revenge porn problem is so difficult to combat and offer suggestions on how to approach a revenge porn solution.   \u2028   For further reading, here are two publications by Amanda Levendowski:\u2028 Using Copyright to Combat Revenge Porn, 3 N.Y.U. J. Intell. Prop. &amp; Ent. L.\u2028Our Best Weapon Against Revenge Porn: Copyright Law?, The Atlantic (Feb. 4, 2014)   \u2028March 5: Claudia Diaz \u2014 \"In PETs we trust: tensions between Privacy Enhancing Technologies and information privacy law\"\u2028The presentation is drawn from a paper, \"Hero or Villain: The Data Controller in Privacy Law and Technologies\u201d with Seda Guerses and Omer Tene.\u2028   February 26: Doc Searls: \"Privacy and Business\"\u2028   ABSTRACT: Thoughtful conversations around privacy (such as ours) have tend come mostly from legal, policy, social and ethical angles. When business comes up, it is often cast in the role of culprit. Today's online advertising business, for example, rationalizes surveillance, dismisses privacy concerns and opposes legislation and regulation protecting privacy. So, in today's privacy climate, one might ask, Can privacy be good for business? and, Can business be good for privacy? Doc Searls' answer to both questions is yes. Through ProjectVRM at Harvard's Berkman Center, Doc has been fostering developments that empower individuals as independent actors in the marketplace since 2006. The Intention Economy: When Customers Take Charge (Harvard Business Review Press, 2012) summarized that work and where it was headed at that time. Today there are more than a hundred VRM (vendor relationship management) developers, many of which are working specifically on protecting personal privacy and establishing its worth in the marketplace. Doc will report that work, its background, where it is currently headed\u2014and the growing role of privacy as both a market demand and a design goal.   \u2028February 19: Report from the Obfuscation Symposium, including brief tool demos and individual impressions\u2028   February 12: Ira Rubinstein: \"The Ethics of Cryptanalysis \u2014 Code Breaking, Exploitation, Subversion and Hacking\"\u2028   ABSTRACT: When it comes to the First Amendment, commerciality does, and should, matter. Building on the work of Meir Dan-Cohen and others, this article develops the view that the key distinguishing characteristic of commercial or corporate speech is that the interest at stake is \u201cderivative,\u201d in the sense that we care about the speech interest for reasons other than caring about the rights of the entity directly asserting a claim under the First Amendment.  Show more/less To say that the interest is derivative is not to say that it is unimportant, and one could find commercial and corporate speech interests to be both derivative and strong enough to apply heightened scrutiny to the restrictions that are the usual subject of debate, namely, restrictions on commercial advertising and restrictions on corporate campaigning. Distinguishing between derivative and intrinsic speech interests, however, helps to uncover two types of situations in which lesser or no scrutiny may be appropriate. The first is in the context of compelled speech. If the entity being compelled is not one whose rights we are concerned with, this undermines the rationale for subjecting speech compulsions to heightened scrutiny under the First Amendment. The second is in the context of speech among commercial entities. In these cases, the transaction may be among entities none of which merit First Amendment concern. Highlighting the difference that commerciality makes helps to explain better certain exceptions, or apparent exceptions, that existing case law already makes to heightened scrutiny, such as with respect to antitrust, securities, or labor law. It also provides insight in a number of current controversies, such as that over cigarette labeling. It has particularly important implications for consumer privacy regulation, suggesting that regulation of both the consumer data trade and commercial data collection merit significantly less scrutiny than might be applied to restrictions on the privacy-invasive practices of ordinary individuals.   \u2028   February 5: Felix Wu \u2014 \"The Commercial Difference\" which grows out of a piece just published in the Chicago Forum called The Constitutionality of Consumer Privacy Regulation\u2028January 29: Organizational meeting     Fall 2013   December 4: Akiva Miller \u2014 Are access and correction tools, opt-out buttons, and privacy dashboards the right solutions to consumer data privacy?\" &amp; Malte Ziewitz: \"What does transparency conceal?\".\u2028November 20: Nathan Newman \u2014 \"Can Government Mandate Union Access to Employer Property? On Corporate Control of Information Flows in the Workplace\"   \u2028ABSTRACT: A basic question of labor law over the years has been how government can intervene to ensure that workers receive information needed to exercise their rights? A contrary concern has been what rights do property owners have under the 1st, 4th, 5th amendments and under federal labor law to restrict that information flow, both in their own interest and in interests claimed on behalf of their employees? Show more/less  A number of existing and proposed law by state governments\u2014including one before the Supreme Court this term\u2014have sought to mandate physical access to employer property to be able to contact employees and/or customers. Since the goal of unions in gaining that access is to develop a \"map\" of the workplace, including a strong analysis of all social networks\u2014who is friends with whom, churches and organizations people are affiliated with, and any other useful social information\u2014such mandated access amounts to government granting an independent party access to a range of social network information about individuals in a workplace. Obviously, employers have their own power in the workplace, so the government strengthening this de facto bottom-up data mining by unions has historically been one of the key counter weights to that corporate power in the workplace. However, the Supreme Court has in recent decades struck down requirements by the NLRB to require that unions be given access to employer property in the name of state property rights and may this term strike down a state law mandating access in the name of the first amendment rights of the employer. This tilt of the law towards protecting employer rights to control data flow in their workplace has been a key factor in weakening labor unions and, as many argue, expanding economic inequality over the last generation. An implication of this analysis is: if a rights-based framework over information in the workplace has ill-served workers, are there implications for whether a rights-based framework over privacy may ill-serve consumers and citizens in broader debates on privacy and data collection?     \u2028November 6: Karen Levy \u2014 \"Beating the Box: Digital Enforcement and Resistance\"   \u2028ABSTRACT: I\u2019ll be presenting some research from my dissertation, which (broadly) explores digital enforcement strategies \u2013 the use of technologies in place or in support of traditional human rule enforcement regimes as a means to enact more \u2018perfect\u2019 behavioral regulation over subjects.  Show more/less Specifically, my research concerns new federal regulations mandating the electronic monitoring of long-haul truck drivers\u2019 work time. Last year in PRG, I talked about how the organizational knowledge practices of trucking firms change around the proliferation of monitoring devices and divest truckers of occupational autonomy. This time around, I\u2019d like to focus on two different areas: First, I explore how truckers (and others) resist monitoring using a variety of technical and organizational strategies, including physical tampering, data manipulation, and [something I\u2019m calling] \u2018collaborative omission.\u2019 These tactics serve to construct new gaps between regulatory intent and social practice. But I could use your help in thinking them through in a more systematic way. Second, I consider the challenges faced by law enforcement officers\u2014specifically, commercial vehicle inspectors\u2014when enforcement efforts are augmented by machines. I\u2019m finding that human/machine hybridity creates several challenges on the ground for these officers, including [something I\u2019m calling] \u2018decoy compliance\u2019 among drivers that obfuscates actual legal noncompliance, as well as a last-mile problem in acquiring data from digital monitors in the trucks.   \u2028   October 23: Brian Choi \u2014 \"The Third-Party Doctrine and the Required-Records Doctrine: Informational Reciprocals, Asymmetries, and Tributaries\"\u2028   ABSTRACT: Even as many have assailed the third-party doctrine and predicted its impending demise, few have heeded the parallel threat posed by the required-records doctrine. Although the third-party doctrine has been widely criticized as an overbroad exception to the Fourth Amendment, defining a coherent limiting principle has proved exceedingly difficult.  Show more/less The popular \u201cmosaic\u201d theory explains how the aggregation of many seemingly insignificant pieces of data from third parties can reveal comprehensive pictures of private activity ordinarily shielded by the Fourth Amendment. Yet, the inherent paradox of the mosaic theory is that it undercuts the project of distinguishing between third-party data that should be accessible without judicial warrant and third-party data that should not. Likewise, the required-records doctrine\u2014which excludes records kept in compliance with general purpose recordkeeping requirements from the Fifth Amendment privilege against self-incrimination\u2014has been so troubling that it has remained largely dormant since its creation. Efforts to construct a coherent limiting principle have been similarly lacking. Nevertheless, a recent set of tax enforcement cases has resuscitated the required-records doctrine and extended it to compel production of offshore bank account records from individual taxpayers. It is no coincidence that the third party doctrine also grew out of a tax enforcement case, holding that individual taxpayers may not shield financial records held by third-party banks. Three insights can be drawn from the project. The first is a warning that the required records doctrine is poised to follow in the footsteps of the third party doctrine. In both contexts, many of the early cases involved requests for financial records needed to prove tax evasion. With the third party doctrine, those early cases quickly generalized to encompass any document in the possession of a third party, including phone records, loan records, medical records, and more. With the required records doctrine, there is a similar shoddiness in the governing standard that would easily allow the same scope creep. If we dislike the current state of the third party doctrine, we should be wary of retracing the same steps under a different guise. Second, the juxtaposition provides a frame for unraveling our discomfort with both the required records doctrine and the third party doctrine. The easy cases might be those involving data that is readily obtainable through both avenues (e.g., duplicate records such as pay stubs or insurance forms), and those that are off limits under both doctrines (e.g., private diaries). On the other hand, the most vexing cases might be those involving data that can be obtained only through one avenue but not the other\u2014allowing the government to pit one Amendment against another. For example, in the moment where a document is required but has not yet been created, that document still exists in thought only; the required records doctrine could demand it but the third party doctrine would not be able to reach it. That asymmetry also explains our discomfort with commercial aggregators who collect massive databases of personal information that the required records doctrine could never demand. Finally, the required records doctrine is a direct tributary of the third party doctrine, and has played a key role in shaping its watershed. Because business entities cannot assert the Fifth Amendment privilege, many businesses are automatically subject to recordkeeping and reporting requirements. Since the required data can include information about customers or other private citizens, the required records doctrine multiplies the potency of the third party doctrine.   \u2028   October 16: Seda G\u00fcerses \u2014 \"Privacy is Don't Ask, Confidentiality is Don't Tell\"\u2028   ABSTRACT: Since the end of the 60s, computer scientists have engaged in research on privacy and information systems. Over the years, this research has led to a whole palette of \"privacy solutions''.  Show more/less These solutions originate from diverse sub-fields of computer science, e.g., security engineering, databases, software engineering, HCI, and artificial intelligence. From a bird's eye view, all of these researchers are studying privacy. However, a closer look reveals that each community of researchers relies on different, sometimes even conflicting, definitions of privacy, and on a variety of social and technical assumptions. These researchers do have a tradition of assessing the (implicit) definitions and assumptions that underlie the studies in their respective sub-disciplines. However, a systematic evaluation of privacy research practice across the different computer science communities is so far absent. I hope to contribute to closing this research gap by presenting the preliminary results of an empirical study of privacy research in computer science.     October 9: Katherine Strandburg \u2014 \"Freedom of Association Constraints on Metadata Surveillance\"\u2028   ABSTRACT: Documents leaked this past summer confirm that the National Security Agency has acquired access to a huge database of domestic call traffic data, revealing information about times, dates, and numbers called.  Show more/less Although communication content traditionally has been the primary focus of concern about overreaching government surveillance, officials are increasingly interested in using sophisticated computer analysis of noncontent traffic data to \u201cmap\u201d networks of associations. Despite the rising importance of digitally mediated association, current Fourth Amendment and statutory schemes provide only weak checks on government. The potential to chill association through overreaching relational surveillance is great. This Article argues that the First Amendment\u2019s freedom of association guarantees can and do provide a proper framework for regulating relational surveillance and suggests how these guarantees might apply to particular forms of analysis of traffic data.   \u2028   October 2: Joris van Hoboken \u2014 \"A Right to be Forgotten\"\u2028   ABSTRACT: In this talk I will present my ongoing work on the so-called 'right to be forgotten' and the underlying questions relating to balancing privacy and freedom of expression in the context of online services.  Show more/less  This right to be forgotten was officially proposed in 2012 by the European Commission as a new element of the EU data protection rules. I will discuss the policy backgrounds of this proposal for a strengthened right to erasure and in particular its relation to new types of publicity facilitated by online intermediaries (search engines and social media in particular). As is clear from an analysis of the proposal which I recently conducted for the European Commission (attached as background) the right to be forgotten has captured the attention of many but fails to address let alone solve the hard issues on the interface of data privacy law, media law and intermediary liability regulations. While the EC proposal may actually be considered 'a right to be forgotten', the underlying questions of how to regulate personal data in online services remain.   \u2028   May 1: Akiva Miller \u2014 \"What Do We Worry About When We Worry About Price Discrimination\"\u2028Readings: Price Discrimination Table: Incomplete Thesis\u2028   April 24: Hannah Block-Wheba and Matt Zimmerman \u2014 National Security Letters [NSL's]\u2028   April 17: Heather Patterson \u2014 \"Contextual Expectations of Privacy in User-Generated Mobile Health Data: The Fitbit Story\"\u2028April 10: Katherine Strandburg \u2014 ECPA Reform; Catherine Crump: Cotterman Case; Paula Helm: Anonymity in AA\u2028   April 3: Ira Rubinstein \u2014 \"Voter Privacy: A Modest Proposal\"   March 27: \"Privacy News Hot Topics\" \u2014 US v. Cotterman, Drones' Hearings, Google Settlement, Employee Health Information Vulnerabilities, and a Report from Differential Privacy Day\u2028March 6: Mariana Thibes \u2014 \"Privacy at Stake, Challenging Issues in the Brazillian Context\"\u2028   March 13: Nathan Newman \u2014 \"The Economics of Information in Behavioral Advertising Markets\"\u2028   February 27: Katherine Strandburg \u2014 \"Free Fall: The Online Market's Consumer Preference Disconnect\"\u2028   February 20: Brad Smith \u2014 \"Privacy at Microsoft\"   Readings: Healthcare Entities, Cloud-Based IT Services, and Privacy Requirement; FERPA and the Cloud: Why FERPA Desperately Needs Reform; From a Cloud Service Provider: The Importance of Keeping Your School's Data Safe; Microsoft response to the Ministry of Justice Call for Evidence on EU Data Protection Proposal - Regulation COM(2012)   \u2028F ebruary 13: Joe Bonneau \u2014 \"What will it mean for privacy as user authentication moves beyond passwords?\"\u2028   February 6: Helen Nissenbaum \u2014 \"The (Privacy) Trouble with MOOCs\"\u2028January 30: Welcome meeting and discussion on current privacy news   September 11: Organizational meeting\u2028   September 18: Discussion - NSA/Pew Survey\u2028   September 25: Luke Stark \u2014 \"The Emotional Context of Information Privacy\"     Fall 2012   December 5: Martin French \u2014 \"Preparing for the Zombie Apocalypse: The Privacy Implications of (Contemporary Developments in) Public Health Intelligence\"\u2028   November 7: Sophie Hood \u2014 \"New Media Technology and the Courts: Judicial Videoconferencing\"\u2028November 14: Travis Hall \u2014 \"Cracks in the Foundation: India's Biometrics Programs and the Power of the Exception\"   \u2028November 28: Scott Bulua and Catherine Crump \u2014 \"A framework for understanding and regulating domestic drone surveillance\"\u2028   November 21: Lital Helman \u2014 \"Corporate Responsibility of Social Networking Platforms\"\u2028   October 24: Matt Tierney and Ian Spiro \u2014 \"Cryptogram: Photo Privacy in Social Media\"\u2028   October 17: Frederik Zuiderveen Borgesius \u2014 \"Behavioural Targeting. How to regulate?\"   \u2028October 10: Discussion of 'Model Law'\u2028   October 3: Agatha Cole \u2014 \"The Role of IP address Data in Counter-Terrorism Operations &amp; Criminal Law Enforcement Investigations: Looking towards the European framework as a model for U.S. Data Retention Policy\"\u2028   September 26: Karen Levy \u2014 \"Privacy, Professionalism, and Techno-Legal Regulation of U.S. Truckers\"\u2028September 19: Nathan Newman \u2014 \"Cost of Lost Privacy: Google, Antitrust and Control of User Data\"                                                    Facebook   Twitter   YouTube   Instagram   Visitor Information   Directories   Offices and Departments   Site Map   NYU School of Law                   Prospective Info   Admissions (JD) Admissions (LLM/JSD) Areas of Study Degrees Offered Faculty Profiles Campus Map  Academics   Academic Sitemap Course Descriptions Class Schedules NYU Classes Clinics Academic Calendars  Departments   Academic Services Career Services Financial Aid Graduate Affairs (LLM) Hospitality and Events Housing Human Resources Library Operations and Facilities Records and Registration Student Affairs  Tools and Resources   About the Law School Campus Map Directories Law School News Journals Picture Book                      \u00a9 2015 New York University School of Law. 40 Washington Sq. South, New York, NY 10012. Tel. (212) 998-6100"}]},
{"detail": [{"content": "Privacy Research Group | NYU School of Law                          Skip to main content                                     &rsaquo;               Quicklinks       Areas of Study   Calendar   Career Services   Colloquia   Courses   Departments   Directories   Docket   Housing   Library   News and Press   NYU Home   Student Links   Technology                                              JD Admissions   Faculty &amp; Scholarship   Global Opportunities   LLM/JSD Admissions   Academics &amp; Courses   Law &amp; Business   Executive Education   Current Students   Public Service   About NYU Law   Alumni &amp; Giving   Centers &amp; Institutes                               Home &rsaquo; Centers &amp; Institutes &rsaquo; Information Law Institute &rsaquo; Privacy Research Group             Privacy Research Group                 Information Law Institute       Events   People   Research   Privacy Research Group   Security Seminar   ILI Student Blog   Contact Us                               \u2028   The Privacy Research Group is a weekly meeting of students, professors, and industry professionals who are passionate about exploring, protecting, and understanding privacy in the digital age.     Joining PRG:   Because we deal with early-stage work in progress, attendance at meetings of the Privacy Research Group is generally limited to researchers and students who can commit to ongoing participation in the group. To discuss joining the group, please contact Professor Helen Nissenbaum or Professor Katherine Strandburg. If you are interested in these topics, but cannot commit to ongoing participation in PRG, you may wish to join the PRG-All mailing list.     PRG Calendar   Spring 2015   April 29: Cases, Controversies, Technologies\u2028   April 22: Helen Nissenbaum - Respect for Context' as a Benchmark for Privacy: What it is and Isn't   April 15: Joris van Hoboken - From Collection to Use Regulation? A Comparative Perspective   ABSTRACT: In the debates about data privacy for the 21st century, we increasingly hear the argument hat regulation should focus on the use of data instead of its initial collection. The argument for this shift tends to be pragmatic: the collection of personal data has become the normal state of affairs to such an extent that focusing the regulation of personal data driven processes through limiting the collection of data (input) is no longer feasible and desirable. Instead, regulation should focus on issues related to the actual use (output). This paper will look at this position from a comparative perspective. It will first explore the different positions that have been expressed in the relevant literature, look at the position of data (collection) minimization and purpose limitation in the US and European regulatory systems and analyze them in comparative perspective, focusing on the different rationales underlying the regulation of \u2018collection\u2019 on the one hand, and \u2018use\u2019 on the other hand.   April 8: Bilyana Petkova\u2028 - Privacy and Federated Law-Making in the EU and the US: Defying the Status Quo?   ABSTRACT: The federated nature of lawmaking in both the United States and the European Union is seen to deliver sub-optimal results. In particular, in the US there are concerns for the increased fragmentation of American data privacy law and the lack of relevant federal consolidation, whereas in the EU the proposed General Data Protection Regulation and overall data protection regime generated opposition regarding the over-centralization of powers to the European institutions. My argument is that the autonomy of state institutions and regulatory experimentation on the state level can defy the status quo, be that of too little or too much privacy consolidation. I look into the role of Member States\u2019 parliaments and highest courts in the EU and of state attorneys general in the US. Arguably, regulatory experimentation with higher data privacy standards in individual states like Germany or California has the potential of generating a dynamic of horizontal adaptation among jurisdictions and industry players that the federal or EU tier can capitalize on to level up privacy protection.   April 1: Paula Kift \u2014 Metadata: An Ontological and Normative Analysis\u2028   ABSTRACT: When the legality of the bulk telephony metadata program was challenged, the NSA countered that it was not collecting the content but only the metadata of communications. The aim of this paper is to discover where the distinction between metadata and content data came from and whether this distinction still makes sense today. The first part of the paper relies on Klayman v. Obama and ACLU v. Clapper to look at the various dichotomies the courts have used to define metadata over time: content vs. non-content information, sensitive vs. non-sensitive information and private records vs. business records held by third parties. The second part of the paper engages in a normative analysis of the bulk telephony metadata program based on the framework of contextual integrity. The paper finds that the bulk telephony metadata program violates entrenched informational norms.\u2028   March 25: Alex Lipton \u2014 Privacy Protections for the Secondary User of Consumer-Watching Technologies\u2028   ABSTRACT: Consumer products increasingly record user data without regard to whether the recorded individual is the primary user\u2014the purchaser of the product\u2014or the secondary user\u2014an individual who uses the product but is not the purchaser. This distinction proves especially significant when considering the product's privacy policy, which purports to establish user consent to expansive data use practices, and statutory protections governing the recording of user data, many of which include exceptions based on user consent. This Note examines one private regime for protecting consumer privacy\u2014privacy policies\u2014and several public regimes\u2014including state wiretap laws, the Electronic Communications Privacy Act, and the Children's Online Privacy Protection Act\u2014to illustrate how legal protections differ for primary and secondary users of consumer-watching technologies. I conclude by suggesting a framework for designing privacy protections for the secondary user of consumer-watching technologies.\u2028   March 11: Rebecca Weinstein (Cancelled\u2028)   March 4: Karen Levy &amp; Alice Marwick \u2014 Unequal Harms: Socioeconomic Status, Race, and Gender in Privacy Research\u2028   ABSTRACT: (NOTE: this is a nascent idea and we're envisioning PRG as primarily a time for discussion of these issues, rather than a research presentation. We'll do a short presentation and then open it up to the group.) While privacy and surveillance affect different populations in disparate ways (Gilman 2012), they are often treated as a monolithic concept by privacy researchers. Show more/less  While researchers in disciplines like women\u2019s studies, sociology, and criminology have examined the impact of the welfare system (Eubanks 2006), the criminal justice system (Goffman 2014), and differential access to technology on privacy (Vickery 2014), these issues may not be labeled or easily recognized as privacy-related by the mainstream of privacy scholarship. Examining the major academic privacy conferences and scholarship of the last few years leads to the conclusion that the normative subject of much privacy research is middle-class, white, and male. However, it is the researchers, think-tank directors, advocates and activists attending these conferences whose work often informs public policy. By incorporating research that is often left out by privacy scholars, and by advocating for projects that discuss more diverse conceptualizations of \u201cthe user\u201d or the subject, we can envision a future for privacy policy that incorporates a wider set of harms and needs, and encompasses the concerns of a larger base of citizens.     \u2028February 25 : Luke Stark \u2014 NannyScam: The Normalization of Consumer-as-Surveillorm\u2028   ABSTRACT: With the proliferation of surveillance technologies in the developed world over the past decade, norms of surveillance are appearing in novel forms and new ways across the terrain of everyday life. While there has been much academic scrutiny of certain aspects of this trend, such as surveillance in the workplace, the collection and analysis of consumer data through loyalty cards and other mechanisms, and location tracking through mobile digital devices, this paper explores an under-studied facet of quotidian surveillance: the construction of a new subject position, that of the consumer not just as surveilled but as also as surveillor. Show more/less The technologies and practices that are acting together to constitute this subject position are not new in themselves _ these include the by-now familiar processes of online self-service, by which consumers are asked to navigate and analyze algorithmic systems in search for their desired product; consumer-grade surveillance products, which have progressed from nanny-cams and baby monitors to the much maligned Elf on the Shelf toy; and most recent and perhaps most troubling, systems of public facing service-sector surveillance (such as Domino\u2019s Pizza\u2019s online order tracker) that give consumers oversight over service-sector workers without control or autonomy on either side. I argue that the confluence of these three sets of technical and social infrastructures places consumers midway within in a hierarchy of everyday surveillance, recreating familiar inequalities of power, access and influence in the process. These systems require not only a material infrastructure for the normalization of surveillance, but also an ideological and emotional one. I suggest that making consumers responsible for the surveillance not only of their own affairs but also the work of others classified as subordinate to them (such as children, service workers, and members of other disenfranchised groups) positions the figure of the consumer as the emotional manager of the experience of surveillance, and reifies a broader material trend within late capitalism: the equation of financial wealth with moral weight in a hierarchy of oversight that gives the wealthiest the most control and least accountability. Implicated within a chain of surveillance that has colonial echoes, the play of everyday social relations have thus become integrated into the broader networks of digital surveillance overseen by governments and corporate actors. In the paper, I will lay out a taxonomy of both historical and contemporary consumer surveillance products and services that supports my analysis above. I will explore how two trends _ infantilization and expectations around parental power and responsibility, and the history of workplace surveillance _ have become models for the transference of surveillance norms to consumers. Based on these models, I will examine possible legal and policy remedies for the political and social challenges posed by the normalization of the consumer-as-surveillor. These include wellknown problems around a lack of what Cohen terms \u201csemantic discontinuities within daily life, leading to the diminution of creativity, agency and human flourishing; concerns also include the normalization of the emotional toll not simply of state surveillance, but also surveillance by one\u2019s fellow citizens in ways reminiscent of the living conditions within totalitarian states.     \u2028February 18: Brian Choi // A Prospect Theory of Privacy\u2028   ABSTRACT: Privacy law differs from other information law doctrines in that it is guided almost exclusively by moral intuition. What qualifies as a \u201cviolation\u201d of privacy turns in large part on the moral reprehensibility of the act in question. By stark contrast, the intellectual property regimes are led primarily by economic considerations, and only secondarily by non-economic factors.  Show more/less Likewise, free speech doctrine is dominated by the value-agnostic \u201cmarketplace of ideas.\u201d In other words, the major disconnect between intellectual \u201cprivacy\u201d and intellectual \u201cproperty\u201d has been the relative priority assigned to the individual\u2019s right to control versus the social cost-benefit of proscribing access by others. Yet, if data is a commodity of value, then the cultivation of such data is a social good, not just an individual entitlement. Where moral rhetoric has failed to advance robust recognition of privacy interests, utilitarian frameworks may prove more effective. In particular, prospect theory offers several useful insights. First, prospect theory posits that individuals should be allowed to rely on more than secrecy to guard informational resources. Presently, because recognition of privacy claims is weak, the production of private data depends heavily on secrecy. Thus, people will either invest in increasingly costly secrecy measures or opt out of the data economy entirely. Both lead to immense social waste. Second, prospect theory suggests that the assignment of informational rights encourages the sharing of information, thus reducing duplicative efforts to generate data. In the patent regime, the goal is commercialization of invention to promote the useful arts. In the privacy regime, the goal is the advancement of social progress through the collective pooling of private experience\u2014which would otherwise remain stashed away. By viewing private data as a valuable commodity to be cultivated, rather than as an inevitable outgrowth of human interaction, we can lend fresh perspective as to what privacy is for.   \u2028   February 11: Aimee Thomson \u2014 Cellular Dragnet: Active Cell Site Simulators and the Fourth Amendment\u2028   ABSTRACT: This Paper examines government use of active cell site simulators (ACSSs) and concludes that ACSS operations constitute a Fourth Amendment search. An ACSS known colloquially as a stingray, triggerfish, or dirtbox mimics a cell phone tower, forcing nearby cell phones to register with the device and divulge identifying and location information. Show more/less  Law enforcement officials regularly use ACSSs to identify and locate individuals, often with extreme precision, while sweeping up the identifying and location information of hundreds or thousands of third parties in the process. Despite the pervasive use of ACSSs at federal, state, and local levels, law enforcement duplicity concerning ACSS operations has prevented courts from closely examining their constitutionality. ACSS operations constitute a Fourth Amendment search under both the trespass paradigm and theprivacy paradigm. Within the former, an ACSS emits radio signals that trespass on private \"effects.\" Under the Jones reinvigoration of the trespass paradigm, radio signals \"touch\" cell phones for the purpose of obtaining information, constituting a Fourth Amendment trespass. Radio signals also trespass under common law property and tort regimes, and the Paper proposes a new rule, consistent with existing trespass jurisprudence, to target only those radio signals that intentionally and without consent cause an active physical change in the cell phone. Within the latter, ACSS operations constitute a Fourth Amendment search because they violate users' subjective expectations of privacy that society can and should recognize as reasonable, particularly if Fourth Amendment jurisprudence continues to eliminate secrecy as a proxy for privacy. Until courts decisively recognize warrantless ACSS operations as illegal, however, advocates and litigants can implement several interim remedial measures. An ACSS is an undeniably valuable law enforcement tool. Subjecting ACSS operations to Fourth Amendment strictures will not hinder their utility but rather ensure that this powerfully invasive technology is not abused.   \u2028   February 4: Ira Rubinstein \u2014 Anonymity and Risk\u2028   ABSTRACT: The possibility of re-identifying anonymized data sets has sparked one of the most lively and important debates in privacy law. The credibility of anonymization, which anchors much of privacy law, is now open to attack. Critics of anonymization argue that almost any data set is vulnerable to a re-identification attack given the inevitability of related data becoming publicly available over time.  Show more/less  Defenders of anonymization counter that despite the theoretical and demonstrated ability to mount such attacks, the likelihood of re-identification for most data sets remains minimal. As a practical matter, they argue, most data sets will remain anonymized using established techniques. Both sides of this debate are now entrenched in their positions, making increasingly technical arguments that are siloed from other relevant aspects of privacy law. As a result, a consensus is elusive. This article aims to help resolve this impasse between formalists (for whom mathematical proof is the touchstone of any meaningful policy) and pragmatists (for whom workable solutions always prevail over theoretical concerns) by reframing the debate away from the endpoint of anonymity and toward the process of risk management. In order to develop a clear, flexible, and workable legal framework for de-identification, we propose drawing from the related, more established area of data security. The law of data security is focused on mandating processes that decrease the likelihood of harm, even if threats are remote. Because there is no such thing as perfect protection, data security policy is decidedly focused on protocols, organizational structure, and the implementation of safeguards. Data security policy also largely refrains from overly-specific rules, deferring instead to a reasonable adherence to industry standards. As the motivation for a consistent approach to de-identify data increases, industry standards will inevitably develop in coordination with public policy and consumer protection goals. A reasonableness approach is also capable of incorporating both legal and technical solutions to the re-identification problem where appropriate. An effective strategy would be to combine contractual prohibitions prohibiting re-identification with scientific approaches to de-identification such as differential privacy and k-anonymity. In short, the law of de-identification should look more like the law of data security: process-based, contextual, and tolerant of risk. Our proposal also argues against a full embrace of the pragmatism and status quo advocated by defenders of anonymization. To begin with, the way this issue is framed is a problem. We join the critics in arguing that the terms \u201canonymous\u201d and \u201canonymization\u201d should be abandoned in our policy and discourse. Almost all uses of the term to describe data sets are misleading if not deceptive. Focusing on the language of risk will better set expectations. Additionally, anonymization critics have rightfully pointed out it is a mistake to overly rely upon risk assessments that cannot account for new data inputs and increasingly sophisticated analytical techniques. An effective risk-based approach to de-identification should accommodate risk models as well as important baseline protections for consumers. In this article, we aim to move past the criticism and defense of anonymization to propose a policy-driven and comprehensive risk-based de-identification framework. Risk-based de-identification should do at least four things: 1) Cover all foreseeably personal data; 2) Tether degree of obligation and punishment to risk; 3) Embrace the full scope of potential harms and available remedies; and, perhaps most controversially, 4) Minimize or eliminate \u201crelease and forget\u201d data sets. Risk-based de-identification is capable of bridging the gap between the formalists and the pragmatists. The approach recognizes that there is no perfect anonymity. Its focus is on process rather than endpoints. Yet effective risk-based de-identification also avoids a ruthless pragmatism by acknowledging the limits of current risk projection models and building in important protections for individual privacy. This policy-driven, integrated, and comprehensive approach will help us advance this important debate into the next stage of implementation.   \u2028   January 28: Scott Skinner-Thomson \u2014 Outing Privacy\u2028   ABSTRACT:The government regularly outs information concerning people\u2019s sexuality, gender identity, and HIV-status. Notwithstanding the implications of such outings, the Supreme Court has yet to answer whether the Constitution contains a right to informational privacy\u2014a right to limit the government\u2019s ability to collect and disseminate personal information.  Show more/less In fact, the Court has on three occasions reluctantly \u201cassumed\u201d that there is such a right without authoritatively recognizing the right or defining its contours. This Article probes informational privacy theory and jurisprudence in order to better understand why the judiciary has been reluctant to fully embrace a robust constitutional right to informational privacy. In short, the Article argues that while existing theories of informational privacy beneficially encourage us to broadly imagine the right and its possibilities, often focusing on informational privacy\u2019s ability to promote individual dignity and autonomy, there is often a disconnect when courts attempt to translate current theories into workable doctrine. The Article reorients and hones the focus of the purported right to informational privacy toward what the Due Process Clause suggests as the right\u2019s two principal and more concrete values: preventing intimate, personal information from serving as the basis for potential discrimination and creating space for the formation of political thought. By so doing, not only is a more precise theory of informational privacy constructed, but, instrumentally (and perhaps most importantly), courts will be more apt to recognize a constitutional informational privacy right and individuals will be better insulated from discrimination or marginalization on the basis of their intimate information or political beliefs.       Fall 2014   December 3: Katherine Strandburg \u2014 Discussion of Privacy News [which can include recent court decisions, new technologies or significant industry practices]\u2028   November 19: Alice Marwick \u2014 Scandal or Sex Crime? Ethical and Privacy Implications of the Celebrity Nude Photo Leaks\u2028   November 12: Elana Zeide \u2014 Student Data and Educational Ideals: examining the current student privacy landscape and how emerging information practice and reforms implicate long-standing social and legal traditions surrounding education in America. The Proverbial Permanent Record [PDF]\u2028   November 5: Seda Guerses \u2014 Let's first get things done! On division of labor and practices of delegation in times of mediated politics and politicized technologies   \u2028ABSTRACT: During particular historical junctures, characterized by crisis, deepening exploitation and popular revolt, referred to here as \u201csneaky moments\u201d, hegemonic hierarchies are simultaneously challenged and reinvented, and in case of the latter in due course subtly reproduced. The current divide between those engaged in politics of technology and those participating in struggles of social justice requires reflection in this context.  Show more/less  We argue that especially the delegation of technological matters to the experienced \"techies\" or \"technological platforms\", and the corresponding flattening of politics and all political activities in the process of developing technical tools and platforms, exacerbate this problem. These tangible divergences in daily practice, however, are not only due to philosophical or political differences. They are also related to the ways in which specialization of work and scarcity of resources leads to a division of labor that often expresses itself across existing fault-lines of race, gender, class and age. Assuming that these moments in which collectives fall back on hegemonic divisions of labor are part and parcel of the divergence between technology politics and social justice politics, we want to ask: are these divisions of labor inevitable? In this paper that is still in progress, we specifically look at the rise of consciousness about surveillance programs post-MENA uprisings as well as Snowden revelations, and the way the counter-surveillance technology campaigns that ensued reconfigured the division of labor between social justice and tech freedom activists. Given the urgency of the moment as well as the momentum created in response to the revelations and news about government surveillance programs, numerous digital rights and freedoms organizations joined campaigns to promote encryption toolkits that \"enhance privacy\" and \"reset the net\" for \"users around the globe\". Through a close reading of these campaign websites, their forms of narration, vocabulary, design decisions, as well as their editorial and technical decisions, we explore how work has been divided between 'techies' and 'activists' and consider ways in which things could have been different.   \u2028   October 29:   Luke Stark \u2014 Discussion on whether \u201cnotice\u201d can continue to play a viable role in protecting privacy in mediated communications and transactions given the increasing complexity of the data ecology and economy.   Kristen Martin \u2014 Transaction costs, privacy, and trust: The laudable goals and ultimate failure of notice and choice to respect privacy online\u2028 Ryan Calo \u2014 Against Notice Skepticism in Privacy (and Elsewhere)\u2028 Lorrie Faith Cranor \u2014 Necessary but Not Sufficient: Standardized Mechanisms for Privacy Notice and Choice.\u2028 October 22: Matthew Callahan \u2014 Warrant Canaries and Law Enforcement Responses. \u2028As background, he recommends reading, \"Twitter's First Amendment Suit &amp; the Warrant Canary Question\" by Brett Max Kaufman in the Just Security blog.\u2028 October 15: Karen Levy \u2014 Networked Resistance to Electronic Surveillance. \u2028October 8: Joris van Hoboken \u2014 The Right to be Forgotten Judgement in Europe: Taking Stock and Looking Ahead\u2028 October 1: Giancarlo Lee \u2014 Automatic Anonymization of Medical Documents.\u2028 September 24: Christopher Sprigman \u2014 MSFT \"Extraterritorial Warrants\" Issue \u2028September 17: Sebastian Zimmeck \u2014 Privee: An Architecture for Automatically Analyzing Web Privacy Policies [with Steven M. Bellovin].\u2028 September 10: Organizational meeting.     Spring 2014   April 30: Seda Guerses \u2014 \"Privacy is Security is a prerequisite for Privacy is not Security is a delegation relationship\"\u2028   ABSTRACT: Since the end of the 60s, computer scientists have engaged in research on privacy and information systems. Over the years, this research has led to a whole palette of \u201cprivacy solutions.\u201d These solutions originate from diverse sub-fields of computer science, e.g., security engineering, databases, software engineering, HCI, and artificial intelligence.  Show more/less From a bird\u2019s eye view, all of these researchers are studying privacy. However, a closer look reveals that each community of researchers relies on different, sometimes even conflicting, definitions of privacy, and on a variety of social and technical assumptions. For example, a good number of privacy researchers define privacy in terms of a known \"security property\": confidentiality. Others contest this approach and suggest that the binary understanding of privacy as concealment and violation of privacy as exposure is too simplistic and at times misleading. During my talk, I will lay out some of the elements of this particular contestation. I will do so by presenting the way in which the interplay between privacy and security is articulated by some of the researchers who participated in an empirical study of privacy research within computer science. This will be a follow up of my PRG presentation in the Fall of 2013, where I presented some of the privacy definitions and conflicting assumptions as they were articulated by differential privacy researchers, data analysts and security engineers.   \u2028   April 23: Milbank Tweed Forum Speaker \u2014 Brad Smith: \"The Future of Privacy\".\u2028   April 16: Solon Barocas \u2014 \"How Data Mining Discriminates\" - a collaborative project with Andrew Selbst, 2012-13 ILI Fellow   \u2028ABSTRACT: This presentation considers recent computer science scholarship on non-discriminatory data mining that has demonstrated\u2014unwittingly, in some cases\u2014the inherent limits of the notion of procedural fairness that grounds anti-discrimination law and the impossibility of avoiding a normative position on the fairness of specific outcomes.\u2028April 9: Florencia Marotta-Wurgler \u2014 \"The Anatomy of Privacy\" - initial findings from her empirical study on privacy policies\u2028April 2: Elana Zeide\u2014 \"Student Privacy in Context: Intuition, Ignorance and Trust\"\u2028March 26: Heather Patterson \u2014 \"When Health Information Goes Rogue: Privacy and Ethical Implications of Decentextualized Information Flows from Consumer Mobile Fitness Devices to Clinician, Insurers, and Employers\"\u2028ABSTRACT: The rapid proliferation of health apps, digital sensors, and other participatory personal data collection devices points to an increasingly personalized future of health care, whereby individuals will track their own physiological and behavioral biomarkers in near real time and receive tailored feedback from an expanding team of commercial entities, social networks, and clinical care providers.  Show more/less Although much of the data processed by commercial sensors and apps is closely aligned with\u2014and sometimes identical to\u2014traditional health care data, its privacy and security are generally not subject to federal or state health privacy regulations by virtue of being held by non-HIPAA covered entities. Worryingly, the collection, integration, analysis, and distribution of this commercially tracked health data may expose individuals to the very privacy and security consequences that health privacy laws were developed to prevent, potentially disrupting the values of the health care system itself. This Article discusses technological, regulatory, and social drivers of digital health technology, reviews privacy harms associated with mobile self-tracking devices\u2014focusing particularly on unconstrained and decontextualized information flows mediated by commercial \u201chealth data intermediaries\u201d\u2014and argues that the likely absorption of sensor data into the traditional medial ecosystem will present challenges to consumer privacy that current regulations are insufficient to address. It proposes that modern health privacy regimes ought to more fully take into account new data flow practices presented by emerging health technologies, both by affirmatively granting health technology users the right to exercise granular and contextual controls over their own health data, and by adopting by default an anti-discrimination framework preventing employers and insurers from penalizing individuals for health inferences made about them from sensors and other \u201cInternet of Things\u201d technologies.     March 12: Scott Bulua &amp; Amanda Levendowski \u2014 Challenges in Combatting Revenge Porn\u2028   ABSTRACT: Revenge porn - sexually explicit images that are publicly shared online, without the consent of the pictured individual - has become the a hot button issue for journalists and academics, lawyers and activists.  Show more/less  The phenomenon is surprisingly common: According to a McAfee survey, one in ten former partners threaten to post sexually explicit images of their exes online. An estimated 60 percent follow through. The harms caused by revenge porn can be very real - people featured on these sites often receive solicitations over social media, lose their jobs, or live in fear that their families and future employers will discover the photos. We will examine the challenges of combatting revenge porn: websites hosting this kind of content are afforded broad immunity under the Communications Decency Act Section 230; existing stalking and harassment laws rarely apply to the conduct of revenge porn submitters and websites; few privacy torts encompass the behaviors of revenge porn submitters; proposed legislation often runs afoul of the First Amendment. Our discussion will center on why the revenge porn problem is so difficult to combat and offer suggestions on how to approach a revenge porn solution.   \u2028   For further reading, here are two publications by Amanda Levendowski:\u2028 Using Copyright to Combat Revenge Porn, 3 N.Y.U. J. Intell. Prop. &amp; Ent. L.\u2028Our Best Weapon Against Revenge Porn: Copyright Law?, The Atlantic (Feb. 4, 2014)   \u2028March 5: Claudia Diaz \u2014 \"In PETs we trust: tensions between Privacy Enhancing Technologies and information privacy law\"\u2028The presentation is drawn from a paper, \"Hero or Villain: The Data Controller in Privacy Law and Technologies\u201d with Seda Guerses and Omer Tene.\u2028   February 26: Doc Searls: \"Privacy and Business\"\u2028   ABSTRACT: Thoughtful conversations around privacy (such as ours) have tend come mostly from legal, policy, social and ethical angles. When business comes up, it is often cast in the role of culprit. Today's online advertising business, for example, rationalizes surveillance, dismisses privacy concerns and opposes legislation and regulation protecting privacy. So, in today's privacy climate, one might ask, Can privacy be good for business? and, Can business be good for privacy? Doc Searls' answer to both questions is yes. Through ProjectVRM at Harvard's Berkman Center, Doc has been fostering developments that empower individuals as independent actors in the marketplace since 2006. The Intention Economy: When Customers Take Charge (Harvard Business Review Press, 2012) summarized that work and where it was headed at that time. Today there are more than a hundred VRM (vendor relationship management) developers, many of which are working specifically on protecting personal privacy and establishing its worth in the marketplace. Doc will report that work, its background, where it is currently headed\u2014and the growing role of privacy as both a market demand and a design goal.   \u2028February 19: Report from the Obfuscation Symposium, including brief tool demos and individual impressions\u2028   February 12: Ira Rubinstein: \"The Ethics of Cryptanalysis \u2014 Code Breaking, Exploitation, Subversion and Hacking\"\u2028   ABSTRACT: When it comes to the First Amendment, commerciality does, and should, matter. Building on the work of Meir Dan-Cohen and others, this article develops the view that the key distinguishing characteristic of commercial or corporate speech is that the interest at stake is \u201cderivative,\u201d in the sense that we care about the speech interest for reasons other than caring about the rights of the entity directly asserting a claim under the First Amendment.  Show more/less To say that the interest is derivative is not to say that it is unimportant, and one could find commercial and corporate speech interests to be both derivative and strong enough to apply heightened scrutiny to the restrictions that are the usual subject of debate, namely, restrictions on commercial advertising and restrictions on corporate campaigning. Distinguishing between derivative and intrinsic speech interests, however, helps to uncover two types of situations in which lesser or no scrutiny may be appropriate. The first is in the context of compelled speech. If the entity being compelled is not one whose rights we are concerned with, this undermines the rationale for subjecting speech compulsions to heightened scrutiny under the First Amendment. The second is in the context of speech among commercial entities. In these cases, the transaction may be among entities none of which merit First Amendment concern. Highlighting the difference that commerciality makes helps to explain better certain exceptions, or apparent exceptions, that existing case law already makes to heightened scrutiny, such as with respect to antitrust, securities, or labor law. It also provides insight in a number of current controversies, such as that over cigarette labeling. It has particularly important implications for consumer privacy regulation, suggesting that regulation of both the consumer data trade and commercial data collection merit significantly less scrutiny than might be applied to restrictions on the privacy-invasive practices of ordinary individuals.   \u2028   February 5: Felix Wu \u2014 \"The Commercial Difference\" which grows out of a piece just published in the Chicago Forum called The Constitutionality of Consumer Privacy Regulation\u2028January 29: Organizational meeting     Fall 2013   December 4: Akiva Miller \u2014 Are access and correction tools, opt-out buttons, and privacy dashboards the right solutions to consumer data privacy?\" &amp; Malte Ziewitz: \"What does transparency conceal?\".\u2028November 20: Nathan Newman \u2014 \"Can Government Mandate Union Access to Employer Property? On Corporate Control of Information Flows in the Workplace\"   \u2028ABSTRACT: A basic question of labor law over the years has been how government can intervene to ensure that workers receive information needed to exercise their rights? A contrary concern has been what rights do property owners have under the 1st, 4th, 5th amendments and under federal labor law to restrict that information flow, both in their own interest and in interests claimed on behalf of their employees? Show more/less  A number of existing and proposed law by state governments\u2014including one before the Supreme Court this term\u2014have sought to mandate physical access to employer property to be able to contact employees and/or customers. Since the goal of unions in gaining that access is to develop a \"map\" of the workplace, including a strong analysis of all social networks\u2014who is friends with whom, churches and organizations people are affiliated with, and any other useful social information\u2014such mandated access amounts to government granting an independent party access to a range of social network information about individuals in a workplace. Obviously, employers have their own power in the workplace, so the government strengthening this de facto bottom-up data mining by unions has historically been one of the key counter weights to that corporate power in the workplace. However, the Supreme Court has in recent decades struck down requirements by the NLRB to require that unions be given access to employer property in the name of state property rights and may this term strike down a state law mandating access in the name of the first amendment rights of the employer. This tilt of the law towards protecting employer rights to control data flow in their workplace has been a key factor in weakening labor unions and, as many argue, expanding economic inequality over the last generation. An implication of this analysis is: if a rights-based framework over information in the workplace has ill-served workers, are there implications for whether a rights-based framework over privacy may ill-serve consumers and citizens in broader debates on privacy and data collection?     \u2028November 6: Karen Levy \u2014 \"Beating the Box: Digital Enforcement and Resistance\"   \u2028ABSTRACT: I\u2019ll be presenting some research from my dissertation, which (broadly) explores digital enforcement strategies \u2013 the use of technologies in place or in support of traditional human rule enforcement regimes as a means to enact more \u2018perfect\u2019 behavioral regulation over subjects.  Show more/less Specifically, my research concerns new federal regulations mandating the electronic monitoring of long-haul truck drivers\u2019 work time. Last year in PRG, I talked about how the organizational knowledge practices of trucking firms change around the proliferation of monitoring devices and divest truckers of occupational autonomy. This time around, I\u2019d like to focus on two different areas: First, I explore how truckers (and others) resist monitoring using a variety of technical and organizational strategies, including physical tampering, data manipulation, and [something I\u2019m calling] \u2018collaborative omission.\u2019 These tactics serve to construct new gaps between regulatory intent and social practice. But I could use your help in thinking them through in a more systematic way. Second, I consider the challenges faced by law enforcement officers\u2014specifically, commercial vehicle inspectors\u2014when enforcement efforts are augmented by machines. I\u2019m finding that human/machine hybridity creates several challenges on the ground for these officers, including [something I\u2019m calling] \u2018decoy compliance\u2019 among drivers that obfuscates actual legal noncompliance, as well as a last-mile problem in acquiring data from digital monitors in the trucks.   \u2028   October 23: Brian Choi \u2014 \"The Third-Party Doctrine and the Required-Records Doctrine: Informational Reciprocals, Asymmetries, and Tributaries\"\u2028   ABSTRACT: Even as many have assailed the third-party doctrine and predicted its impending demise, few have heeded the parallel threat posed by the required-records doctrine. Although the third-party doctrine has been widely criticized as an overbroad exception to the Fourth Amendment, defining a coherent limiting principle has proved exceedingly difficult.  Show more/less The popular \u201cmosaic\u201d theory explains how the aggregation of many seemingly insignificant pieces of data from third parties can reveal comprehensive pictures of private activity ordinarily shielded by the Fourth Amendment. Yet, the inherent paradox of the mosaic theory is that it undercuts the project of distinguishing between third-party data that should be accessible without judicial warrant and third-party data that should not. Likewise, the required-records doctrine\u2014which excludes records kept in compliance with general purpose recordkeeping requirements from the Fifth Amendment privilege against self-incrimination\u2014has been so troubling that it has remained largely dormant since its creation. Efforts to construct a coherent limiting principle have been similarly lacking. Nevertheless, a recent set of tax enforcement cases has resuscitated the required-records doctrine and extended it to compel production of offshore bank account records from individual taxpayers. It is no coincidence that the third party doctrine also grew out of a tax enforcement case, holding that individual taxpayers may not shield financial records held by third-party banks. Three insights can be drawn from the project. The first is a warning that the required records doctrine is poised to follow in the footsteps of the third party doctrine. In both contexts, many of the early cases involved requests for financial records needed to prove tax evasion. With the third party doctrine, those early cases quickly generalized to encompass any document in the possession of a third party, including phone records, loan records, medical records, and more. With the required records doctrine, there is a similar shoddiness in the governing standard that would easily allow the same scope creep. If we dislike the current state of the third party doctrine, we should be wary of retracing the same steps under a different guise. Second, the juxtaposition provides a frame for unraveling our discomfort with both the required records doctrine and the third party doctrine. The easy cases might be those involving data that is readily obtainable through both avenues (e.g., duplicate records such as pay stubs or insurance forms), and those that are off limits under both doctrines (e.g., private diaries). On the other hand, the most vexing cases might be those involving data that can be obtained only through one avenue but not the other\u2014allowing the government to pit one Amendment against another. For example, in the moment where a document is required but has not yet been created, that document still exists in thought only; the required records doctrine could demand it but the third party doctrine would not be able to reach it. That asymmetry also explains our discomfort with commercial aggregators who collect massive databases of personal information that the required records doctrine could never demand. Finally, the required records doctrine is a direct tributary of the third party doctrine, and has played a key role in shaping its watershed. Because business entities cannot assert the Fifth Amendment privilege, many businesses are automatically subject to recordkeeping and reporting requirements. Since the required data can include information about customers or other private citizens, the required records doctrine multiplies the potency of the third party doctrine.   \u2028   October 16: Seda G\u00fcerses \u2014 \"Privacy is Don't Ask, Confidentiality is Don't Tell\"\u2028   ABSTRACT: Since the end of the 60s, computer scientists have engaged in research on privacy and information systems. Over the years, this research has led to a whole palette of \"privacy solutions''.  Show more/less These solutions originate from diverse sub-fields of computer science, e.g., security engineering, databases, software engineering, HCI, and artificial intelligence. From a bird's eye view, all of these researchers are studying privacy. However, a closer look reveals that each community of researchers relies on different, sometimes even conflicting, definitions of privacy, and on a variety of social and technical assumptions. These researchers do have a tradition of assessing the (implicit) definitions and assumptions that underlie the studies in their respective sub-disciplines. However, a systematic evaluation of privacy research practice across the different computer science communities is so far absent. I hope to contribute to closing this research gap by presenting the preliminary results of an empirical study of privacy research in computer science.     October 9: Katherine Strandburg \u2014 \"Freedom of Association Constraints on Metadata Surveillance\"\u2028   ABSTRACT: Documents leaked this past summer confirm that the National Security Agency has acquired access to a huge database of domestic call traffic data, revealing information about times, dates, and numbers called.  Show more/less Although communication content traditionally has been the primary focus of concern about overreaching government surveillance, officials are increasingly interested in using sophisticated computer analysis of noncontent traffic data to \u201cmap\u201d networks of associations. Despite the rising importance of digitally mediated association, current Fourth Amendment and statutory schemes provide only weak checks on government. The potential to chill association through overreaching relational surveillance is great. This Article argues that the First Amendment\u2019s freedom of association guarantees can and do provide a proper framework for regulating relational surveillance and suggests how these guarantees might apply to particular forms of analysis of traffic data.   \u2028   October 2: Joris van Hoboken \u2014 \"A Right to be Forgotten\"\u2028   ABSTRACT: In this talk I will present my ongoing work on the so-called 'right to be forgotten' and the underlying questions relating to balancing privacy and freedom of expression in the context of online services.  Show more/less  This right to be forgotten was officially proposed in 2012 by the European Commission as a new element of the EU data protection rules. I will discuss the policy backgrounds of this proposal for a strengthened right to erasure and in particular its relation to new types of publicity facilitated by online intermediaries (search engines and social media in particular). As is clear from an analysis of the proposal which I recently conducted for the European Commission (attached as background) the right to be forgotten has captured the attention of many but fails to address let alone solve the hard issues on the interface of data privacy law, media law and intermediary liability regulations. While the EC proposal may actually be considered 'a right to be forgotten', the underlying questions of how to regulate personal data in online services remain.   \u2028   May 1: Akiva Miller \u2014 \"What Do We Worry About When We Worry About Price Discrimination\"\u2028Readings: Price Discrimination Table: Incomplete Thesis\u2028   April 24: Hannah Block-Wheba and Matt Zimmerman \u2014 National Security Letters [NSL's]\u2028   April 17: Heather Patterson \u2014 \"Contextual Expectations of Privacy in User-Generated Mobile Health Data: The Fitbit Story\"\u2028April 10: Katherine Strandburg \u2014 ECPA Reform; Catherine Crump: Cotterman Case; Paula Helm: Anonymity in AA\u2028   April 3: Ira Rubinstein \u2014 \"Voter Privacy: A Modest Proposal\"   March 27: \"Privacy News Hot Topics\" \u2014 US v. Cotterman, Drones' Hearings, Google Settlement, Employee Health Information Vulnerabilities, and a Report from Differential Privacy Day\u2028March 6: Mariana Thibes \u2014 \"Privacy at Stake, Challenging Issues in the Brazillian Context\"\u2028   March 13: Nathan Newman \u2014 \"The Economics of Information in Behavioral Advertising Markets\"\u2028   February 27: Katherine Strandburg \u2014 \"Free Fall: The Online Market's Consumer Preference Disconnect\"\u2028   February 20: Brad Smith \u2014 \"Privacy at Microsoft\"   Readings: Healthcare Entities, Cloud-Based IT Services, and Privacy Requirement; FERPA and the Cloud: Why FERPA Desperately Needs Reform; From a Cloud Service Provider: The Importance of Keeping Your School's Data Safe; Microsoft response to the Ministry of Justice Call for Evidence on EU Data Protection Proposal - Regulation COM(2012)   \u2028F ebruary 13: Joe Bonneau \u2014 \"What will it mean for privacy as user authentication moves beyond passwords?\"\u2028   February 6: Helen Nissenbaum \u2014 \"The (Privacy) Trouble with MOOCs\"\u2028January 30: Welcome meeting and discussion on current privacy news   September 11: Organizational meeting\u2028   September 18: Discussion - NSA/Pew Survey\u2028   September 25: Luke Stark \u2014 \"The Emotional Context of Information Privacy\"     Fall 2012   December 5: Martin French \u2014 \"Preparing for the Zombie Apocalypse: The Privacy Implications of (Contemporary Developments in) Public Health Intelligence\"\u2028   November 7: Sophie Hood \u2014 \"New Media Technology and the Courts: Judicial Videoconferencing\"\u2028November 14: Travis Hall \u2014 \"Cracks in the Foundation: India's Biometrics Programs and the Power of the Exception\"   \u2028November 28: Scott Bulua and Catherine Crump \u2014 \"A framework for understanding and regulating domestic drone surveillance\"\u2028   November 21: Lital Helman \u2014 \"Corporate Responsibility of Social Networking Platforms\"\u2028   October 24: Matt Tierney and Ian Spiro \u2014 \"Cryptogram: Photo Privacy in Social Media\"\u2028   October 17: Frederik Zuiderveen Borgesius \u2014 \"Behavioural Targeting. How to regulate?\"   \u2028October 10: Discussion of 'Model Law'\u2028   October 3: Agatha Cole \u2014 \"The Role of IP address Data in Counter-Terrorism Operations &amp; Criminal Law Enforcement Investigations: Looking towards the European framework as a model for U.S. Data Retention Policy\"\u2028   September 26: Karen Levy \u2014 \"Privacy, Professionalism, and Techno-Legal Regulation of U.S. Truckers\"\u2028September 19: Nathan Newman \u2014 \"Cost of Lost Privacy: Google, Antitrust and Control of User Data\"                                                    Facebook   Twitter   YouTube   Instagram   Visitor Information   Directories   Offices and Departments   Site Map   NYU School of Law                   Prospective Info   Admissions (JD) Admissions (LLM/JSD) Areas of Study Degrees Offered Faculty Profiles Campus Map  Academics   Academic Sitemap Course Descriptions Class Schedules NYU Classes Clinics Academic Calendars  Departments   Academic Services Career Services Financial Aid Graduate Affairs (LLM) Hospitality and Events Housing Human Resources Library Operations and Facilities Records and Registration Student Affairs  Tools and Resources   About the Law School Campus Map Directories Law School News Journals Picture Book                      \u00a9 2015 New York University School of Law. 40 Washington Sq. South, New York, NY 10012. Tel. (212) 998-6100"}, {"content": "Helen Nissenbaum                                              HELEN NISSENBAUM            Professor, New York University       Media, Culture, and Communication & Computer Science       Director, Information Law Institute                         HOME  /  RESEARCH  /  PUBLICATIONS  /  COURSES  /  CV  /  BIO  /  ARCHIVE  /  CONTACT           Links:     Center for Interdisciplinary Studies in Security and Privacy (CRISSP)    Values in Design    Values in Design Council    Privacy Research Group    Information Law Institute    NYU Security Research Seminar    TrackMeNot : Privacy Through Obfuscation    Adnostic : Targeting Without Tracking    Intel Science & Technology Center for Social Computing       Books:    Modulated Cities: Networked Spaces, Reconstituted Subjects , Situated Technologies book series.    Privacy in Context: Technology, Policy, and the Integrity of Social Life , Palo Alto, CA: Stanford University Press, Spanish translation Privacidad Amenazada.    Academy and the Internet , Co-edited with M. Price. New York: Peter Lang Publishing Company, 2004. View Cover & Table of Contents.     Computers, Ethics, and Social Values , Co-edited with D. Johnson. Englewood Cliffs, NJ: Prentice Hall, 1995.    Emotion and Focus , Chicago: The University of Chicago Press, 1985. Available from the Center for the Study of Language and Informations.         What's New:        Algorithms and Accountability Conference Panel Videos    NYU Information Law Institute/MCC Fellows 2014-15: Seda Gurses, Joris van Hoboken, Karen Levy and Elana Zeide     AdNauseam 1.1 H. Nissenbaum, D. Howe and M. Zer-Aviv          Values at Play in Digital Games , H. Nissenbaum and M. Flanagan (MIT Press)            Privacy, Big Data and the Public Good , eds. J. Lane, V. Stodden, S. Bender and H. Nissenbaum.                  Selected Articles:    Big Data's End Run around Anonymity and Consent , with S. Barocas.    Political and Ethical Perspectives on Data Obfuscation , with F. Brunton.    Sustaining both Privacy and Open Justice in the Transition to Online Access to Court Records: A Multidisciplinary Inquiry , with A. Conley, A. Datta, and D. Sharma.    From Preemption to Circumvention: If Technology Regulates Why Do We Need Regulation (and Vice Versa)?    A Contextual Approach to Privacy Online    TrackMeNot 2.0: Enhancing the privacy of Web Search , with V. Toubiana and L. Subramanian.    On Notice: The Trouble with Notice and Consent , with S. Barocas.    TrackMeNot: Resisting Surveillance in Web Search , with D. Howe.    Facial Recognition Technology: A Survey of Policy and Implementation Issues , with L. Introna.     Commons-Based Peer Production and Virtue , with Y. Benkler.    Terms of Service: A Play in One Act , presented at The Symposium on Information Intermediaries in the Information Society    Will Security Enhance Trust Online, or Supplant It?    New Research Norms for a New Medium              Email Helen Nissenbaum Need Help? Web-Master"}]},
{"detail": [{"content": "Privacy Research Group | NYU School of Law                          Skip to main content                                     &rsaquo;               Quicklinks       Areas of Study   Calendar   Career Services   Colloquia   Courses   Departments   Directories   Docket   Housing   Library   News and Press   NYU Home   Student Links   Technology                                              JD Admissions   Faculty &amp; Scholarship   Global Opportunities   LLM/JSD Admissions   Academics &amp; Courses   Law &amp; Business   Executive Education   Current Students   Public Service   About NYU Law   Alumni &amp; Giving   Centers &amp; Institutes                               Home &rsaquo; Centers &amp; Institutes &rsaquo; Information Law Institute &rsaquo; Privacy Research Group             Privacy Research Group                 Information Law Institute       Events   People   Research   Privacy Research Group   Security Seminar   ILI Student Blog   Contact Us                               \u2028   The Privacy Research Group is a weekly meeting of students, professors, and industry professionals who are passionate about exploring, protecting, and understanding privacy in the digital age.     Joining PRG:   Because we deal with early-stage work in progress, attendance at meetings of the Privacy Research Group is generally limited to researchers and students who can commit to ongoing participation in the group. To discuss joining the group, please contact Professor Helen Nissenbaum or Professor Katherine Strandburg. If you are interested in these topics, but cannot commit to ongoing participation in PRG, you may wish to join the PRG-All mailing list.     PRG Calendar   Spring 2015   April 29: Cases, Controversies, Technologies\u2028   April 22: Helen Nissenbaum - Respect for Context' as a Benchmark for Privacy: What it is and Isn't   April 15: Joris van Hoboken - From Collection to Use Regulation? A Comparative Perspective   ABSTRACT: In the debates about data privacy for the 21st century, we increasingly hear the argument hat regulation should focus on the use of data instead of its initial collection. The argument for this shift tends to be pragmatic: the collection of personal data has become the normal state of affairs to such an extent that focusing the regulation of personal data driven processes through limiting the collection of data (input) is no longer feasible and desirable. Instead, regulation should focus on issues related to the actual use (output). This paper will look at this position from a comparative perspective. It will first explore the different positions that have been expressed in the relevant literature, look at the position of data (collection) minimization and purpose limitation in the US and European regulatory systems and analyze them in comparative perspective, focusing on the different rationales underlying the regulation of \u2018collection\u2019 on the one hand, and \u2018use\u2019 on the other hand.   April 8: Bilyana Petkova\u2028 - Privacy and Federated Law-Making in the EU and the US: Defying the Status Quo?   ABSTRACT: The federated nature of lawmaking in both the United States and the European Union is seen to deliver sub-optimal results. In particular, in the US there are concerns for the increased fragmentation of American data privacy law and the lack of relevant federal consolidation, whereas in the EU the proposed General Data Protection Regulation and overall data protection regime generated opposition regarding the over-centralization of powers to the European institutions. My argument is that the autonomy of state institutions and regulatory experimentation on the state level can defy the status quo, be that of too little or too much privacy consolidation. I look into the role of Member States\u2019 parliaments and highest courts in the EU and of state attorneys general in the US. Arguably, regulatory experimentation with higher data privacy standards in individual states like Germany or California has the potential of generating a dynamic of horizontal adaptation among jurisdictions and industry players that the federal or EU tier can capitalize on to level up privacy protection.   April 1: Paula Kift \u2014 Metadata: An Ontological and Normative Analysis\u2028   ABSTRACT: When the legality of the bulk telephony metadata program was challenged, the NSA countered that it was not collecting the content but only the metadata of communications. The aim of this paper is to discover where the distinction between metadata and content data came from and whether this distinction still makes sense today. The first part of the paper relies on Klayman v. Obama and ACLU v. Clapper to look at the various dichotomies the courts have used to define metadata over time: content vs. non-content information, sensitive vs. non-sensitive information and private records vs. business records held by third parties. The second part of the paper engages in a normative analysis of the bulk telephony metadata program based on the framework of contextual integrity. The paper finds that the bulk telephony metadata program violates entrenched informational norms.\u2028   March 25: Alex Lipton \u2014 Privacy Protections for the Secondary User of Consumer-Watching Technologies\u2028   ABSTRACT: Consumer products increasingly record user data without regard to whether the recorded individual is the primary user\u2014the purchaser of the product\u2014or the secondary user\u2014an individual who uses the product but is not the purchaser. This distinction proves especially significant when considering the product's privacy policy, which purports to establish user consent to expansive data use practices, and statutory protections governing the recording of user data, many of which include exceptions based on user consent. This Note examines one private regime for protecting consumer privacy\u2014privacy policies\u2014and several public regimes\u2014including state wiretap laws, the Electronic Communications Privacy Act, and the Children's Online Privacy Protection Act\u2014to illustrate how legal protections differ for primary and secondary users of consumer-watching technologies. I conclude by suggesting a framework for designing privacy protections for the secondary user of consumer-watching technologies.\u2028   March 11: Rebecca Weinstein (Cancelled\u2028)   March 4: Karen Levy &amp; Alice Marwick \u2014 Unequal Harms: Socioeconomic Status, Race, and Gender in Privacy Research\u2028   ABSTRACT: (NOTE: this is a nascent idea and we're envisioning PRG as primarily a time for discussion of these issues, rather than a research presentation. We'll do a short presentation and then open it up to the group.) While privacy and surveillance affect different populations in disparate ways (Gilman 2012), they are often treated as a monolithic concept by privacy researchers. Show more/less  While researchers in disciplines like women\u2019s studies, sociology, and criminology have examined the impact of the welfare system (Eubanks 2006), the criminal justice system (Goffman 2014), and differential access to technology on privacy (Vickery 2014), these issues may not be labeled or easily recognized as privacy-related by the mainstream of privacy scholarship. Examining the major academic privacy conferences and scholarship of the last few years leads to the conclusion that the normative subject of much privacy research is middle-class, white, and male. However, it is the researchers, think-tank directors, advocates and activists attending these conferences whose work often informs public policy. By incorporating research that is often left out by privacy scholars, and by advocating for projects that discuss more diverse conceptualizations of \u201cthe user\u201d or the subject, we can envision a future for privacy policy that incorporates a wider set of harms and needs, and encompasses the concerns of a larger base of citizens.     \u2028February 25 : Luke Stark \u2014 NannyScam: The Normalization of Consumer-as-Surveillorm\u2028   ABSTRACT: With the proliferation of surveillance technologies in the developed world over the past decade, norms of surveillance are appearing in novel forms and new ways across the terrain of everyday life. While there has been much academic scrutiny of certain aspects of this trend, such as surveillance in the workplace, the collection and analysis of consumer data through loyalty cards and other mechanisms, and location tracking through mobile digital devices, this paper explores an under-studied facet of quotidian surveillance: the construction of a new subject position, that of the consumer not just as surveilled but as also as surveillor. Show more/less The technologies and practices that are acting together to constitute this subject position are not new in themselves _ these include the by-now familiar processes of online self-service, by which consumers are asked to navigate and analyze algorithmic systems in search for their desired product; consumer-grade surveillance products, which have progressed from nanny-cams and baby monitors to the much maligned Elf on the Shelf toy; and most recent and perhaps most troubling, systems of public facing service-sector surveillance (such as Domino\u2019s Pizza\u2019s online order tracker) that give consumers oversight over service-sector workers without control or autonomy on either side. I argue that the confluence of these three sets of technical and social infrastructures places consumers midway within in a hierarchy of everyday surveillance, recreating familiar inequalities of power, access and influence in the process. These systems require not only a material infrastructure for the normalization of surveillance, but also an ideological and emotional one. I suggest that making consumers responsible for the surveillance not only of their own affairs but also the work of others classified as subordinate to them (such as children, service workers, and members of other disenfranchised groups) positions the figure of the consumer as the emotional manager of the experience of surveillance, and reifies a broader material trend within late capitalism: the equation of financial wealth with moral weight in a hierarchy of oversight that gives the wealthiest the most control and least accountability. Implicated within a chain of surveillance that has colonial echoes, the play of everyday social relations have thus become integrated into the broader networks of digital surveillance overseen by governments and corporate actors. In the paper, I will lay out a taxonomy of both historical and contemporary consumer surveillance products and services that supports my analysis above. I will explore how two trends _ infantilization and expectations around parental power and responsibility, and the history of workplace surveillance _ have become models for the transference of surveillance norms to consumers. Based on these models, I will examine possible legal and policy remedies for the political and social challenges posed by the normalization of the consumer-as-surveillor. These include wellknown problems around a lack of what Cohen terms \u201csemantic discontinuities within daily life, leading to the diminution of creativity, agency and human flourishing; concerns also include the normalization of the emotional toll not simply of state surveillance, but also surveillance by one\u2019s fellow citizens in ways reminiscent of the living conditions within totalitarian states.     \u2028February 18: Brian Choi // A Prospect Theory of Privacy\u2028   ABSTRACT: Privacy law differs from other information law doctrines in that it is guided almost exclusively by moral intuition. What qualifies as a \u201cviolation\u201d of privacy turns in large part on the moral reprehensibility of the act in question. By stark contrast, the intellectual property regimes are led primarily by economic considerations, and only secondarily by non-economic factors.  Show more/less Likewise, free speech doctrine is dominated by the value-agnostic \u201cmarketplace of ideas.\u201d In other words, the major disconnect between intellectual \u201cprivacy\u201d and intellectual \u201cproperty\u201d has been the relative priority assigned to the individual\u2019s right to control versus the social cost-benefit of proscribing access by others. Yet, if data is a commodity of value, then the cultivation of such data is a social good, not just an individual entitlement. Where moral rhetoric has failed to advance robust recognition of privacy interests, utilitarian frameworks may prove more effective. In particular, prospect theory offers several useful insights. First, prospect theory posits that individuals should be allowed to rely on more than secrecy to guard informational resources. Presently, because recognition of privacy claims is weak, the production of private data depends heavily on secrecy. Thus, people will either invest in increasingly costly secrecy measures or opt out of the data economy entirely. Both lead to immense social waste. Second, prospect theory suggests that the assignment of informational rights encourages the sharing of information, thus reducing duplicative efforts to generate data. In the patent regime, the goal is commercialization of invention to promote the useful arts. In the privacy regime, the goal is the advancement of social progress through the collective pooling of private experience\u2014which would otherwise remain stashed away. By viewing private data as a valuable commodity to be cultivated, rather than as an inevitable outgrowth of human interaction, we can lend fresh perspective as to what privacy is for.   \u2028   February 11: Aimee Thomson \u2014 Cellular Dragnet: Active Cell Site Simulators and the Fourth Amendment\u2028   ABSTRACT: This Paper examines government use of active cell site simulators (ACSSs) and concludes that ACSS operations constitute a Fourth Amendment search. An ACSS known colloquially as a stingray, triggerfish, or dirtbox mimics a cell phone tower, forcing nearby cell phones to register with the device and divulge identifying and location information. Show more/less  Law enforcement officials regularly use ACSSs to identify and locate individuals, often with extreme precision, while sweeping up the identifying and location information of hundreds or thousands of third parties in the process. Despite the pervasive use of ACSSs at federal, state, and local levels, law enforcement duplicity concerning ACSS operations has prevented courts from closely examining their constitutionality. ACSS operations constitute a Fourth Amendment search under both the trespass paradigm and theprivacy paradigm. Within the former, an ACSS emits radio signals that trespass on private \"effects.\" Under the Jones reinvigoration of the trespass paradigm, radio signals \"touch\" cell phones for the purpose of obtaining information, constituting a Fourth Amendment trespass. Radio signals also trespass under common law property and tort regimes, and the Paper proposes a new rule, consistent with existing trespass jurisprudence, to target only those radio signals that intentionally and without consent cause an active physical change in the cell phone. Within the latter, ACSS operations constitute a Fourth Amendment search because they violate users' subjective expectations of privacy that society can and should recognize as reasonable, particularly if Fourth Amendment jurisprudence continues to eliminate secrecy as a proxy for privacy. Until courts decisively recognize warrantless ACSS operations as illegal, however, advocates and litigants can implement several interim remedial measures. An ACSS is an undeniably valuable law enforcement tool. Subjecting ACSS operations to Fourth Amendment strictures will not hinder their utility but rather ensure that this powerfully invasive technology is not abused.   \u2028   February 4: Ira Rubinstein \u2014 Anonymity and Risk\u2028   ABSTRACT: The possibility of re-identifying anonymized data sets has sparked one of the most lively and important debates in privacy law. The credibility of anonymization, which anchors much of privacy law, is now open to attack. Critics of anonymization argue that almost any data set is vulnerable to a re-identification attack given the inevitability of related data becoming publicly available over time.  Show more/less  Defenders of anonymization counter that despite the theoretical and demonstrated ability to mount such attacks, the likelihood of re-identification for most data sets remains minimal. As a practical matter, they argue, most data sets will remain anonymized using established techniques. Both sides of this debate are now entrenched in their positions, making increasingly technical arguments that are siloed from other relevant aspects of privacy law. As a result, a consensus is elusive. This article aims to help resolve this impasse between formalists (for whom mathematical proof is the touchstone of any meaningful policy) and pragmatists (for whom workable solutions always prevail over theoretical concerns) by reframing the debate away from the endpoint of anonymity and toward the process of risk management. In order to develop a clear, flexible, and workable legal framework for de-identification, we propose drawing from the related, more established area of data security. The law of data security is focused on mandating processes that decrease the likelihood of harm, even if threats are remote. Because there is no such thing as perfect protection, data security policy is decidedly focused on protocols, organizational structure, and the implementation of safeguards. Data security policy also largely refrains from overly-specific rules, deferring instead to a reasonable adherence to industry standards. As the motivation for a consistent approach to de-identify data increases, industry standards will inevitably develop in coordination with public policy and consumer protection goals. A reasonableness approach is also capable of incorporating both legal and technical solutions to the re-identification problem where appropriate. An effective strategy would be to combine contractual prohibitions prohibiting re-identification with scientific approaches to de-identification such as differential privacy and k-anonymity. In short, the law of de-identification should look more like the law of data security: process-based, contextual, and tolerant of risk. Our proposal also argues against a full embrace of the pragmatism and status quo advocated by defenders of anonymization. To begin with, the way this issue is framed is a problem. We join the critics in arguing that the terms \u201canonymous\u201d and \u201canonymization\u201d should be abandoned in our policy and discourse. Almost all uses of the term to describe data sets are misleading if not deceptive. Focusing on the language of risk will better set expectations. Additionally, anonymization critics have rightfully pointed out it is a mistake to overly rely upon risk assessments that cannot account for new data inputs and increasingly sophisticated analytical techniques. An effective risk-based approach to de-identification should accommodate risk models as well as important baseline protections for consumers. In this article, we aim to move past the criticism and defense of anonymization to propose a policy-driven and comprehensive risk-based de-identification framework. Risk-based de-identification should do at least four things: 1) Cover all foreseeably personal data; 2) Tether degree of obligation and punishment to risk; 3) Embrace the full scope of potential harms and available remedies; and, perhaps most controversially, 4) Minimize or eliminate \u201crelease and forget\u201d data sets. Risk-based de-identification is capable of bridging the gap between the formalists and the pragmatists. The approach recognizes that there is no perfect anonymity. Its focus is on process rather than endpoints. Yet effective risk-based de-identification also avoids a ruthless pragmatism by acknowledging the limits of current risk projection models and building in important protections for individual privacy. This policy-driven, integrated, and comprehensive approach will help us advance this important debate into the next stage of implementation.   \u2028   January 28: Scott Skinner-Thomson \u2014 Outing Privacy\u2028   ABSTRACT:The government regularly outs information concerning people\u2019s sexuality, gender identity, and HIV-status. Notwithstanding the implications of such outings, the Supreme Court has yet to answer whether the Constitution contains a right to informational privacy\u2014a right to limit the government\u2019s ability to collect and disseminate personal information.  Show more/less In fact, the Court has on three occasions reluctantly \u201cassumed\u201d that there is such a right without authoritatively recognizing the right or defining its contours. This Article probes informational privacy theory and jurisprudence in order to better understand why the judiciary has been reluctant to fully embrace a robust constitutional right to informational privacy. In short, the Article argues that while existing theories of informational privacy beneficially encourage us to broadly imagine the right and its possibilities, often focusing on informational privacy\u2019s ability to promote individual dignity and autonomy, there is often a disconnect when courts attempt to translate current theories into workable doctrine. The Article reorients and hones the focus of the purported right to informational privacy toward what the Due Process Clause suggests as the right\u2019s two principal and more concrete values: preventing intimate, personal information from serving as the basis for potential discrimination and creating space for the formation of political thought. By so doing, not only is a more precise theory of informational privacy constructed, but, instrumentally (and perhaps most importantly), courts will be more apt to recognize a constitutional informational privacy right and individuals will be better insulated from discrimination or marginalization on the basis of their intimate information or political beliefs.       Fall 2014   December 3: Katherine Strandburg \u2014 Discussion of Privacy News [which can include recent court decisions, new technologies or significant industry practices]\u2028   November 19: Alice Marwick \u2014 Scandal or Sex Crime? Ethical and Privacy Implications of the Celebrity Nude Photo Leaks\u2028   November 12: Elana Zeide \u2014 Student Data and Educational Ideals: examining the current student privacy landscape and how emerging information practice and reforms implicate long-standing social and legal traditions surrounding education in America. The Proverbial Permanent Record [PDF]\u2028   November 5: Seda Guerses \u2014 Let's first get things done! On division of labor and practices of delegation in times of mediated politics and politicized technologies   \u2028ABSTRACT: During particular historical junctures, characterized by crisis, deepening exploitation and popular revolt, referred to here as \u201csneaky moments\u201d, hegemonic hierarchies are simultaneously challenged and reinvented, and in case of the latter in due course subtly reproduced. The current divide between those engaged in politics of technology and those participating in struggles of social justice requires reflection in this context.  Show more/less  We argue that especially the delegation of technological matters to the experienced \"techies\" or \"technological platforms\", and the corresponding flattening of politics and all political activities in the process of developing technical tools and platforms, exacerbate this problem. These tangible divergences in daily practice, however, are not only due to philosophical or political differences. They are also related to the ways in which specialization of work and scarcity of resources leads to a division of labor that often expresses itself across existing fault-lines of race, gender, class and age. Assuming that these moments in which collectives fall back on hegemonic divisions of labor are part and parcel of the divergence between technology politics and social justice politics, we want to ask: are these divisions of labor inevitable? In this paper that is still in progress, we specifically look at the rise of consciousness about surveillance programs post-MENA uprisings as well as Snowden revelations, and the way the counter-surveillance technology campaigns that ensued reconfigured the division of labor between social justice and tech freedom activists. Given the urgency of the moment as well as the momentum created in response to the revelations and news about government surveillance programs, numerous digital rights and freedoms organizations joined campaigns to promote encryption toolkits that \"enhance privacy\" and \"reset the net\" for \"users around the globe\". Through a close reading of these campaign websites, their forms of narration, vocabulary, design decisions, as well as their editorial and technical decisions, we explore how work has been divided between 'techies' and 'activists' and consider ways in which things could have been different.   \u2028   October 29:   Luke Stark \u2014 Discussion on whether \u201cnotice\u201d can continue to play a viable role in protecting privacy in mediated communications and transactions given the increasing complexity of the data ecology and economy.   Kristen Martin \u2014 Transaction costs, privacy, and trust: The laudable goals and ultimate failure of notice and choice to respect privacy online\u2028 Ryan Calo \u2014 Against Notice Skepticism in Privacy (and Elsewhere)\u2028 Lorrie Faith Cranor \u2014 Necessary but Not Sufficient: Standardized Mechanisms for Privacy Notice and Choice.\u2028 October 22: Matthew Callahan \u2014 Warrant Canaries and Law Enforcement Responses. \u2028As background, he recommends reading, \"Twitter's First Amendment Suit &amp; the Warrant Canary Question\" by Brett Max Kaufman in the Just Security blog.\u2028 October 15: Karen Levy \u2014 Networked Resistance to Electronic Surveillance. \u2028October 8: Joris van Hoboken \u2014 The Right to be Forgotten Judgement in Europe: Taking Stock and Looking Ahead\u2028 October 1: Giancarlo Lee \u2014 Automatic Anonymization of Medical Documents.\u2028 September 24: Christopher Sprigman \u2014 MSFT \"Extraterritorial Warrants\" Issue \u2028September 17: Sebastian Zimmeck \u2014 Privee: An Architecture for Automatically Analyzing Web Privacy Policies [with Steven M. Bellovin].\u2028 September 10: Organizational meeting.     Spring 2014   April 30: Seda Guerses \u2014 \"Privacy is Security is a prerequisite for Privacy is not Security is a delegation relationship\"\u2028   ABSTRACT: Since the end of the 60s, computer scientists have engaged in research on privacy and information systems. Over the years, this research has led to a whole palette of \u201cprivacy solutions.\u201d These solutions originate from diverse sub-fields of computer science, e.g., security engineering, databases, software engineering, HCI, and artificial intelligence.  Show more/less From a bird\u2019s eye view, all of these researchers are studying privacy. However, a closer look reveals that each community of researchers relies on different, sometimes even conflicting, definitions of privacy, and on a variety of social and technical assumptions. For example, a good number of privacy researchers define privacy in terms of a known \"security property\": confidentiality. Others contest this approach and suggest that the binary understanding of privacy as concealment and violation of privacy as exposure is too simplistic and at times misleading. During my talk, I will lay out some of the elements of this particular contestation. I will do so by presenting the way in which the interplay between privacy and security is articulated by some of the researchers who participated in an empirical study of privacy research within computer science. This will be a follow up of my PRG presentation in the Fall of 2013, where I presented some of the privacy definitions and conflicting assumptions as they were articulated by differential privacy researchers, data analysts and security engineers.   \u2028   April 23: Milbank Tweed Forum Speaker \u2014 Brad Smith: \"The Future of Privacy\".\u2028   April 16: Solon Barocas \u2014 \"How Data Mining Discriminates\" - a collaborative project with Andrew Selbst, 2012-13 ILI Fellow   \u2028ABSTRACT: This presentation considers recent computer science scholarship on non-discriminatory data mining that has demonstrated\u2014unwittingly, in some cases\u2014the inherent limits of the notion of procedural fairness that grounds anti-discrimination law and the impossibility of avoiding a normative position on the fairness of specific outcomes.\u2028April 9: Florencia Marotta-Wurgler \u2014 \"The Anatomy of Privacy\" - initial findings from her empirical study on privacy policies\u2028April 2: Elana Zeide\u2014 \"Student Privacy in Context: Intuition, Ignorance and Trust\"\u2028March 26: Heather Patterson \u2014 \"When Health Information Goes Rogue: Privacy and Ethical Implications of Decentextualized Information Flows from Consumer Mobile Fitness Devices to Clinician, Insurers, and Employers\"\u2028ABSTRACT: The rapid proliferation of health apps, digital sensors, and other participatory personal data collection devices points to an increasingly personalized future of health care, whereby individuals will track their own physiological and behavioral biomarkers in near real time and receive tailored feedback from an expanding team of commercial entities, social networks, and clinical care providers.  Show more/less Although much of the data processed by commercial sensors and apps is closely aligned with\u2014and sometimes identical to\u2014traditional health care data, its privacy and security are generally not subject to federal or state health privacy regulations by virtue of being held by non-HIPAA covered entities. Worryingly, the collection, integration, analysis, and distribution of this commercially tracked health data may expose individuals to the very privacy and security consequences that health privacy laws were developed to prevent, potentially disrupting the values of the health care system itself. This Article discusses technological, regulatory, and social drivers of digital health technology, reviews privacy harms associated with mobile self-tracking devices\u2014focusing particularly on unconstrained and decontextualized information flows mediated by commercial \u201chealth data intermediaries\u201d\u2014and argues that the likely absorption of sensor data into the traditional medial ecosystem will present challenges to consumer privacy that current regulations are insufficient to address. It proposes that modern health privacy regimes ought to more fully take into account new data flow practices presented by emerging health technologies, both by affirmatively granting health technology users the right to exercise granular and contextual controls over their own health data, and by adopting by default an anti-discrimination framework preventing employers and insurers from penalizing individuals for health inferences made about them from sensors and other \u201cInternet of Things\u201d technologies.     March 12: Scott Bulua &amp; Amanda Levendowski \u2014 Challenges in Combatting Revenge Porn\u2028   ABSTRACT: Revenge porn - sexually explicit images that are publicly shared online, without the consent of the pictured individual - has become the a hot button issue for journalists and academics, lawyers and activists.  Show more/less  The phenomenon is surprisingly common: According to a McAfee survey, one in ten former partners threaten to post sexually explicit images of their exes online. An estimated 60 percent follow through. The harms caused by revenge porn can be very real - people featured on these sites often receive solicitations over social media, lose their jobs, or live in fear that their families and future employers will discover the photos. We will examine the challenges of combatting revenge porn: websites hosting this kind of content are afforded broad immunity under the Communications Decency Act Section 230; existing stalking and harassment laws rarely apply to the conduct of revenge porn submitters and websites; few privacy torts encompass the behaviors of revenge porn submitters; proposed legislation often runs afoul of the First Amendment. Our discussion will center on why the revenge porn problem is so difficult to combat and offer suggestions on how to approach a revenge porn solution.   \u2028   For further reading, here are two publications by Amanda Levendowski:\u2028 Using Copyright to Combat Revenge Porn, 3 N.Y.U. J. Intell. Prop. &amp; Ent. L.\u2028Our Best Weapon Against Revenge Porn: Copyright Law?, The Atlantic (Feb. 4, 2014)   \u2028March 5: Claudia Diaz \u2014 \"In PETs we trust: tensions between Privacy Enhancing Technologies and information privacy law\"\u2028The presentation is drawn from a paper, \"Hero or Villain: The Data Controller in Privacy Law and Technologies\u201d with Seda Guerses and Omer Tene.\u2028   February 26: Doc Searls: \"Privacy and Business\"\u2028   ABSTRACT: Thoughtful conversations around privacy (such as ours) have tend come mostly from legal, policy, social and ethical angles. When business comes up, it is often cast in the role of culprit. Today's online advertising business, for example, rationalizes surveillance, dismisses privacy concerns and opposes legislation and regulation protecting privacy. So, in today's privacy climate, one might ask, Can privacy be good for business? and, Can business be good for privacy? Doc Searls' answer to both questions is yes. Through ProjectVRM at Harvard's Berkman Center, Doc has been fostering developments that empower individuals as independent actors in the marketplace since 2006. The Intention Economy: When Customers Take Charge (Harvard Business Review Press, 2012) summarized that work and where it was headed at that time. Today there are more than a hundred VRM (vendor relationship management) developers, many of which are working specifically on protecting personal privacy and establishing its worth in the marketplace. Doc will report that work, its background, where it is currently headed\u2014and the growing role of privacy as both a market demand and a design goal.   \u2028February 19: Report from the Obfuscation Symposium, including brief tool demos and individual impressions\u2028   February 12: Ira Rubinstein: \"The Ethics of Cryptanalysis \u2014 Code Breaking, Exploitation, Subversion and Hacking\"\u2028   ABSTRACT: When it comes to the First Amendment, commerciality does, and should, matter. Building on the work of Meir Dan-Cohen and others, this article develops the view that the key distinguishing characteristic of commercial or corporate speech is that the interest at stake is \u201cderivative,\u201d in the sense that we care about the speech interest for reasons other than caring about the rights of the entity directly asserting a claim under the First Amendment.  Show more/less To say that the interest is derivative is not to say that it is unimportant, and one could find commercial and corporate speech interests to be both derivative and strong enough to apply heightened scrutiny to the restrictions that are the usual subject of debate, namely, restrictions on commercial advertising and restrictions on corporate campaigning. Distinguishing between derivative and intrinsic speech interests, however, helps to uncover two types of situations in which lesser or no scrutiny may be appropriate. The first is in the context of compelled speech. If the entity being compelled is not one whose rights we are concerned with, this undermines the rationale for subjecting speech compulsions to heightened scrutiny under the First Amendment. The second is in the context of speech among commercial entities. In these cases, the transaction may be among entities none of which merit First Amendment concern. Highlighting the difference that commerciality makes helps to explain better certain exceptions, or apparent exceptions, that existing case law already makes to heightened scrutiny, such as with respect to antitrust, securities, or labor law. It also provides insight in a number of current controversies, such as that over cigarette labeling. It has particularly important implications for consumer privacy regulation, suggesting that regulation of both the consumer data trade and commercial data collection merit significantly less scrutiny than might be applied to restrictions on the privacy-invasive practices of ordinary individuals.   \u2028   February 5: Felix Wu \u2014 \"The Commercial Difference\" which grows out of a piece just published in the Chicago Forum called The Constitutionality of Consumer Privacy Regulation\u2028January 29: Organizational meeting     Fall 2013   December 4: Akiva Miller \u2014 Are access and correction tools, opt-out buttons, and privacy dashboards the right solutions to consumer data privacy?\" &amp; Malte Ziewitz: \"What does transparency conceal?\".\u2028November 20: Nathan Newman \u2014 \"Can Government Mandate Union Access to Employer Property? On Corporate Control of Information Flows in the Workplace\"   \u2028ABSTRACT: A basic question of labor law over the years has been how government can intervene to ensure that workers receive information needed to exercise their rights? A contrary concern has been what rights do property owners have under the 1st, 4th, 5th amendments and under federal labor law to restrict that information flow, both in their own interest and in interests claimed on behalf of their employees? Show more/less  A number of existing and proposed law by state governments\u2014including one before the Supreme Court this term\u2014have sought to mandate physical access to employer property to be able to contact employees and/or customers. Since the goal of unions in gaining that access is to develop a \"map\" of the workplace, including a strong analysis of all social networks\u2014who is friends with whom, churches and organizations people are affiliated with, and any other useful social information\u2014such mandated access amounts to government granting an independent party access to a range of social network information about individuals in a workplace. Obviously, employers have their own power in the workplace, so the government strengthening this de facto bottom-up data mining by unions has historically been one of the key counter weights to that corporate power in the workplace. However, the Supreme Court has in recent decades struck down requirements by the NLRB to require that unions be given access to employer property in the name of state property rights and may this term strike down a state law mandating access in the name of the first amendment rights of the employer. This tilt of the law towards protecting employer rights to control data flow in their workplace has been a key factor in weakening labor unions and, as many argue, expanding economic inequality over the last generation. An implication of this analysis is: if a rights-based framework over information in the workplace has ill-served workers, are there implications for whether a rights-based framework over privacy may ill-serve consumers and citizens in broader debates on privacy and data collection?     \u2028November 6: Karen Levy \u2014 \"Beating the Box: Digital Enforcement and Resistance\"   \u2028ABSTRACT: I\u2019ll be presenting some research from my dissertation, which (broadly) explores digital enforcement strategies \u2013 the use of technologies in place or in support of traditional human rule enforcement regimes as a means to enact more \u2018perfect\u2019 behavioral regulation over subjects.  Show more/less Specifically, my research concerns new federal regulations mandating the electronic monitoring of long-haul truck drivers\u2019 work time. Last year in PRG, I talked about how the organizational knowledge practices of trucking firms change around the proliferation of monitoring devices and divest truckers of occupational autonomy. This time around, I\u2019d like to focus on two different areas: First, I explore how truckers (and others) resist monitoring using a variety of technical and organizational strategies, including physical tampering, data manipulation, and [something I\u2019m calling] \u2018collaborative omission.\u2019 These tactics serve to construct new gaps between regulatory intent and social practice. But I could use your help in thinking them through in a more systematic way. Second, I consider the challenges faced by law enforcement officers\u2014specifically, commercial vehicle inspectors\u2014when enforcement efforts are augmented by machines. I\u2019m finding that human/machine hybridity creates several challenges on the ground for these officers, including [something I\u2019m calling] \u2018decoy compliance\u2019 among drivers that obfuscates actual legal noncompliance, as well as a last-mile problem in acquiring data from digital monitors in the trucks.   \u2028   October 23: Brian Choi \u2014 \"The Third-Party Doctrine and the Required-Records Doctrine: Informational Reciprocals, Asymmetries, and Tributaries\"\u2028   ABSTRACT: Even as many have assailed the third-party doctrine and predicted its impending demise, few have heeded the parallel threat posed by the required-records doctrine. Although the third-party doctrine has been widely criticized as an overbroad exception to the Fourth Amendment, defining a coherent limiting principle has proved exceedingly difficult.  Show more/less The popular \u201cmosaic\u201d theory explains how the aggregation of many seemingly insignificant pieces of data from third parties can reveal comprehensive pictures of private activity ordinarily shielded by the Fourth Amendment. Yet, the inherent paradox of the mosaic theory is that it undercuts the project of distinguishing between third-party data that should be accessible without judicial warrant and third-party data that should not. Likewise, the required-records doctrine\u2014which excludes records kept in compliance with general purpose recordkeeping requirements from the Fifth Amendment privilege against self-incrimination\u2014has been so troubling that it has remained largely dormant since its creation. Efforts to construct a coherent limiting principle have been similarly lacking. Nevertheless, a recent set of tax enforcement cases has resuscitated the required-records doctrine and extended it to compel production of offshore bank account records from individual taxpayers. It is no coincidence that the third party doctrine also grew out of a tax enforcement case, holding that individual taxpayers may not shield financial records held by third-party banks. Three insights can be drawn from the project. The first is a warning that the required records doctrine is poised to follow in the footsteps of the third party doctrine. In both contexts, many of the early cases involved requests for financial records needed to prove tax evasion. With the third party doctrine, those early cases quickly generalized to encompass any document in the possession of a third party, including phone records, loan records, medical records, and more. With the required records doctrine, there is a similar shoddiness in the governing standard that would easily allow the same scope creep. If we dislike the current state of the third party doctrine, we should be wary of retracing the same steps under a different guise. Second, the juxtaposition provides a frame for unraveling our discomfort with both the required records doctrine and the third party doctrine. The easy cases might be those involving data that is readily obtainable through both avenues (e.g., duplicate records such as pay stubs or insurance forms), and those that are off limits under both doctrines (e.g., private diaries). On the other hand, the most vexing cases might be those involving data that can be obtained only through one avenue but not the other\u2014allowing the government to pit one Amendment against another. For example, in the moment where a document is required but has not yet been created, that document still exists in thought only; the required records doctrine could demand it but the third party doctrine would not be able to reach it. That asymmetry also explains our discomfort with commercial aggregators who collect massive databases of personal information that the required records doctrine could never demand. Finally, the required records doctrine is a direct tributary of the third party doctrine, and has played a key role in shaping its watershed. Because business entities cannot assert the Fifth Amendment privilege, many businesses are automatically subject to recordkeeping and reporting requirements. Since the required data can include information about customers or other private citizens, the required records doctrine multiplies the potency of the third party doctrine.   \u2028   October 16: Seda G\u00fcerses \u2014 \"Privacy is Don't Ask, Confidentiality is Don't Tell\"\u2028   ABSTRACT: Since the end of the 60s, computer scientists have engaged in research on privacy and information systems. Over the years, this research has led to a whole palette of \"privacy solutions''.  Show more/less These solutions originate from diverse sub-fields of computer science, e.g., security engineering, databases, software engineering, HCI, and artificial intelligence. From a bird's eye view, all of these researchers are studying privacy. However, a closer look reveals that each community of researchers relies on different, sometimes even conflicting, definitions of privacy, and on a variety of social and technical assumptions. These researchers do have a tradition of assessing the (implicit) definitions and assumptions that underlie the studies in their respective sub-disciplines. However, a systematic evaluation of privacy research practice across the different computer science communities is so far absent. I hope to contribute to closing this research gap by presenting the preliminary results of an empirical study of privacy research in computer science.     October 9: Katherine Strandburg \u2014 \"Freedom of Association Constraints on Metadata Surveillance\"\u2028   ABSTRACT: Documents leaked this past summer confirm that the National Security Agency has acquired access to a huge database of domestic call traffic data, revealing information about times, dates, and numbers called.  Show more/less Although communication content traditionally has been the primary focus of concern about overreaching government surveillance, officials are increasingly interested in using sophisticated computer analysis of noncontent traffic data to \u201cmap\u201d networks of associations. Despite the rising importance of digitally mediated association, current Fourth Amendment and statutory schemes provide only weak checks on government. The potential to chill association through overreaching relational surveillance is great. This Article argues that the First Amendment\u2019s freedom of association guarantees can and do provide a proper framework for regulating relational surveillance and suggests how these guarantees might apply to particular forms of analysis of traffic data.   \u2028   October 2: Joris van Hoboken \u2014 \"A Right to be Forgotten\"\u2028   ABSTRACT: In this talk I will present my ongoing work on the so-called 'right to be forgotten' and the underlying questions relating to balancing privacy and freedom of expression in the context of online services.  Show more/less  This right to be forgotten was officially proposed in 2012 by the European Commission as a new element of the EU data protection rules. I will discuss the policy backgrounds of this proposal for a strengthened right to erasure and in particular its relation to new types of publicity facilitated by online intermediaries (search engines and social media in particular). As is clear from an analysis of the proposal which I recently conducted for the European Commission (attached as background) the right to be forgotten has captured the attention of many but fails to address let alone solve the hard issues on the interface of data privacy law, media law and intermediary liability regulations. While the EC proposal may actually be considered 'a right to be forgotten', the underlying questions of how to regulate personal data in online services remain.   \u2028   May 1: Akiva Miller \u2014 \"What Do We Worry About When We Worry About Price Discrimination\"\u2028Readings: Price Discrimination Table: Incomplete Thesis\u2028   April 24: Hannah Block-Wheba and Matt Zimmerman \u2014 National Security Letters [NSL's]\u2028   April 17: Heather Patterson \u2014 \"Contextual Expectations of Privacy in User-Generated Mobile Health Data: The Fitbit Story\"\u2028April 10: Katherine Strandburg \u2014 ECPA Reform; Catherine Crump: Cotterman Case; Paula Helm: Anonymity in AA\u2028   April 3: Ira Rubinstein \u2014 \"Voter Privacy: A Modest Proposal\"   March 27: \"Privacy News Hot Topics\" \u2014 US v. Cotterman, Drones' Hearings, Google Settlement, Employee Health Information Vulnerabilities, and a Report from Differential Privacy Day\u2028March 6: Mariana Thibes \u2014 \"Privacy at Stake, Challenging Issues in the Brazillian Context\"\u2028   March 13: Nathan Newman \u2014 \"The Economics of Information in Behavioral Advertising Markets\"\u2028   February 27: Katherine Strandburg \u2014 \"Free Fall: The Online Market's Consumer Preference Disconnect\"\u2028   February 20: Brad Smith \u2014 \"Privacy at Microsoft\"   Readings: Healthcare Entities, Cloud-Based IT Services, and Privacy Requirement; FERPA and the Cloud: Why FERPA Desperately Needs Reform; From a Cloud Service Provider: The Importance of Keeping Your School's Data Safe; Microsoft response to the Ministry of Justice Call for Evidence on EU Data Protection Proposal - Regulation COM(2012)   \u2028F ebruary 13: Joe Bonneau \u2014 \"What will it mean for privacy as user authentication moves beyond passwords?\"\u2028   February 6: Helen Nissenbaum \u2014 \"The (Privacy) Trouble with MOOCs\"\u2028January 30: Welcome meeting and discussion on current privacy news   September 11: Organizational meeting\u2028   September 18: Discussion - NSA/Pew Survey\u2028   September 25: Luke Stark \u2014 \"The Emotional Context of Information Privacy\"     Fall 2012   December 5: Martin French \u2014 \"Preparing for the Zombie Apocalypse: The Privacy Implications of (Contemporary Developments in) Public Health Intelligence\"\u2028   November 7: Sophie Hood \u2014 \"New Media Technology and the Courts: Judicial Videoconferencing\"\u2028November 14: Travis Hall \u2014 \"Cracks in the Foundation: India's Biometrics Programs and the Power of the Exception\"   \u2028November 28: Scott Bulua and Catherine Crump \u2014 \"A framework for understanding and regulating domestic drone surveillance\"\u2028   November 21: Lital Helman \u2014 \"Corporate Responsibility of Social Networking Platforms\"\u2028   October 24: Matt Tierney and Ian Spiro \u2014 \"Cryptogram: Photo Privacy in Social Media\"\u2028   October 17: Frederik Zuiderveen Borgesius \u2014 \"Behavioural Targeting. How to regulate?\"   \u2028October 10: Discussion of 'Model Law'\u2028   October 3: Agatha Cole \u2014 \"The Role of IP address Data in Counter-Terrorism Operations &amp; Criminal Law Enforcement Investigations: Looking towards the European framework as a model for U.S. Data Retention Policy\"\u2028   September 26: Karen Levy \u2014 \"Privacy, Professionalism, and Techno-Legal Regulation of U.S. Truckers\"\u2028September 19: Nathan Newman \u2014 \"Cost of Lost Privacy: Google, Antitrust and Control of User Data\"                                                    Facebook   Twitter   YouTube   Instagram   Visitor Information   Directories   Offices and Departments   Site Map   NYU School of Law                   Prospective Info   Admissions (JD) Admissions (LLM/JSD) Areas of Study Degrees Offered Faculty Profiles Campus Map  Academics   Academic Sitemap Course Descriptions Class Schedules NYU Classes Clinics Academic Calendars  Departments   Academic Services Career Services Financial Aid Graduate Affairs (LLM) Hospitality and Events Housing Human Resources Library Operations and Facilities Records and Registration Student Affairs  Tools and Resources   About the Law School Campus Map Directories Law School News Journals Picture Book                      \u00a9 2015 New York University School of Law. 40 Washington Sq. South, New York, NY 10012. Tel. (212) 998-6100"}, {"content": "Helen Nissenbaum                                              HELEN NISSENBAUM            Professor, New York University       Media, Culture, and Communication & Computer Science       Director, Information Law Institute                         HOME  /  RESEARCH  /  PUBLICATIONS  /  COURSES  /  CV  /  BIO  /  ARCHIVE  /  CONTACT           Links:     Center for Interdisciplinary Studies in Security and Privacy (CRISSP)    Values in Design    Values in Design Council    Privacy Research Group    Information Law Institute    NYU Security Research Seminar    TrackMeNot : Privacy Through Obfuscation    Adnostic : Targeting Without Tracking    Intel Science & Technology Center for Social Computing       Books:    Modulated Cities: Networked Spaces, Reconstituted Subjects , Situated Technologies book series.    Privacy in Context: Technology, Policy, and the Integrity of Social Life , Palo Alto, CA: Stanford University Press, Spanish translation Privacidad Amenazada.    Academy and the Internet , Co-edited with M. Price. New York: Peter Lang Publishing Company, 2004. View Cover & Table of Contents.     Computers, Ethics, and Social Values , Co-edited with D. Johnson. Englewood Cliffs, NJ: Prentice Hall, 1995.    Emotion and Focus , Chicago: The University of Chicago Press, 1985. Available from the Center for the Study of Language and Informations.         What's New:        Algorithms and Accountability Conference Panel Videos    NYU Information Law Institute/MCC Fellows 2014-15: Seda Gurses, Joris van Hoboken, Karen Levy and Elana Zeide     AdNauseam 1.1 H. Nissenbaum, D. Howe and M. Zer-Aviv          Values at Play in Digital Games , H. Nissenbaum and M. Flanagan (MIT Press)            Privacy, Big Data and the Public Good , eds. J. Lane, V. Stodden, S. Bender and H. Nissenbaum.                  Selected Articles:    Big Data's End Run around Anonymity and Consent , with S. Barocas.    Political and Ethical Perspectives on Data Obfuscation , with F. Brunton.    Sustaining both Privacy and Open Justice in the Transition to Online Access to Court Records: A Multidisciplinary Inquiry , with A. Conley, A. Datta, and D. Sharma.    From Preemption to Circumvention: If Technology Regulates Why Do We Need Regulation (and Vice Versa)?    A Contextual Approach to Privacy Online    TrackMeNot 2.0: Enhancing the privacy of Web Search , with V. Toubiana and L. Subramanian.    On Notice: The Trouble with Notice and Consent , with S. Barocas.    TrackMeNot: Resisting Surveillance in Web Search , with D. Howe.    Facial Recognition Technology: A Survey of Policy and Implementation Issues , with L. Introna.     Commons-Based Peer Production and Virtue , with Y. Benkler.    Terms of Service: A Play in One Act , presented at The Symposium on Information Intermediaries in the Information Society    Will Security Enhance Trust Online, or Supplant It?    New Research Norms for a New Medium              Email Helen Nissenbaum Need Help? Web-Master"}, {"content": "ILI Student Blog | Information Law, Policy and Digital Privacy                                             ILI Student Blog   Information Law, Policy and Digital Privacy                                                                    College Rape Case Shows A Key Limit To Medical Privacy Law      April 23, 2015 4:52 pm // 0 Comments         April 23rd, 2015   College Rape Case Shows A Key Limit To Medical Privacy Law   By: Ryusuke Tanaka   [...]                                         Reflections on D.C. Administration\u2019s Proposed Exemption of Police Body Camera Footage Disclosure      April 23, 2015 4:50 pm // 0 Comments         April 23rd, 2015   Reflections on D.C. Administration\u2019s Proposed Exemption of Police Body Camera Footage [...]                                         Fitness apps may pose legal problems for doctors      April 23, 2015 11:44 am // 0 Comments         April 23rd, 2015   Fitness apps may pose legal problems for doctors   By: Emma Trotter   The February 2015 [...]                                         Which Federal Agency Should Regulate Health Apps?      April 22, 2015 9:15 am // 0 Comments         April 21, 2015   By: Rachel Wisotsky   Which Federal Agency Should Regulate Health [...]                                         Data Privacy, the French Alps Crash, the Nazis and the TTIP      April 20, 2015 10:52 am // 0 Comments         April 20th, 2015   Data Privacy, the French Alps Crash, the Nazis and the TTIP   By: [...]                                         EU Council&#8217;s Agreement and the \u201cOne-Stop Shop\u201d      April 16, 2015 4:58 pm // 0 Comments         April 16th, 2015   EU Council&#8217;s Agreement and the [...]                                         Facebook in trouble with EU Privacy watchdogs again!      April 16, 2015 3:15 pm // 0 Comments         April 16, 2015   Panel 2   Facebook in trouble with EU Privacy watchdogs again!   [...]                                         PRG News Roundup: April 15th      April 16, 2015 5:40 am // 0 Comments         New York Appellate court finds voyeuristic photographer protected under first amendment:   [...]                                         US Senators Proposes New Privacy Bill to regulate Data brokers      April 14, 2015 8:58 am // 0 Comments         April 14th, 2015   US Senators Proposes New Privacy Bill to regulate Data brokers   By Luis [...]                                         Talking Barbie      April 9, 2015 4:11 pm // 0 Comments         April 9th, 2015   Talking Barbie   By: Rugeradh Tungsupakul   According to the recent toy [...]      1   2   3   &hellip;   32   &raquo;         Welcome!     Welcome to New York University's Information Law Institute (ILI) student blog. If you have any questions, please contact the webmaster by clicking here .  This page is sponsored by New York University's Information Law Institute .       Recent Comments tunugol1 on May 1 Panel 1  Marc's Voice &raquo; Middle of Nov. 2013 blogging on Are access and correction tools, opt-out buttons, and privacy dashboards the right solutions to consumer data privacy? Aimee on Setting up Accounts at PRG  Nathan Newman on Setting up Accounts at PRG Aimee on Setting up Accounts at PRG       Copyright &copy; 2015 | WordPress Theme by MH Themes"}]}]