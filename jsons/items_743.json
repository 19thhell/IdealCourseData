[{"detail": [{"content": "NYU/Courant Theory Seminar                 NYU CS Theory Seminar                              Usual coordinates:     Friday, 2:15PM    Room 1314    Warren Weaver Hall    251 Mercer Street                  Spring 2015 Schedule       Upcoming talks                                                       Thursday April 16         3:00PM         WWH 201                                                         Ankur Moitra (MIT)                                          Tensor Prediction, Rademacher Complexity and Random 3-XOR                                [+]                                           Abstract: Here we study the tensor prediction problem, where the goal is to accurately predict the entries of a low rank,          third-order tensor (with noise) given as few observations as possible. We give algorithms based on the sixth level of the          sum-of-squares hierarchy that work with roughly m = n^3/2 observations, and we complement our result by showing that any          attempt to solve tensor prediction with fewer observations through the sum-of-squares hierarchy would run in moderately          exponential time. In contrast, information theoretically roughly m = n observations suffice.                     This work is part of a broader agenda of studying computational vs. statistical tradeoffs through the sum-of-squares hierarchy.          In particular, for linear inverse problems (such as tensor prediction) the natural sum-of-squares relaxation gives rise to a          sequence of norms. Our approach is to characterize their Rademacher complexity. Moreover, both our upper and lower bounds are          based on connections between this, and the task of strongly refuting random 3-XOR formulas, and the resolution proof system.                     This talk is based on joint work with Boaz Barak                                                                               Friday April 24         2:15PM         WWH 1314                                                         Yuval Filmus (IAS)                                         On the Coppersmith-Winograd approach to matrix multiplication                                [+]                                           Abstract:          Ever since Strassen's O(n^{2.81}) matrix multiplication algorithm stunned the mathematical community,          the quest for fast matrix multiplication algorithms has been a holy grail in computer science.          At first progress was fast, culminating in Coppersmith and Winograd's O(n^{2.376}) algorithm of 1987.          Recently interest in the area has reawakened due to work of Stothers, Vassilevska-Williams and Le Gall,          who managed to improve the exponent slightly from 2.376 to 2.373.                     Roughly speaking, Coppersmith and Winograd constructed an edifice turning an \"identity\"          (some kind of mathematical object) into a fast matrix multiplication algorithm.          Applying their method on the identity TCW, they obtained an O(n^{2.388}) algorithm.          Applying it to TCW^2 (identities can be squared!), they obtained their O(n^{2.376}) algorithm.          They stopped there since computing was a lot more cumbersome in the 1980s.          Using modern computers, Stothers, Vassilevska-Williams and Le Gall were able to analyze          higher powers of TCW (up to TCW^32), and so reduced the exponent to 2.373.                     Our talk answers the following question:                      What is the limit of this approach?                                 We show that this approach cannot yield an exponent smaller than 2.372.          No prior knowledge will be assumed.                     Joint work with Andris Ambainis (University of Latvia) and Francois Le Gall (University of Tokyo).                                                                               Friday May 1         2:15PM         WWH 1314                                                         Ilya Razenshteyn (MIT)                                         TBD                                [+]                                           Abstract: TBD                                                                             Friday May 8         2:15PM         WWH 1314                                                         David Sontag (NYU)                                         How Good Is Structured Prediction?                                [+]                                           Abstract: Many machine learning tasks can be posed as structured prediction,          where the goal is to predict a labeling or structured object. For          example, the input may be an image or a sentence, and the output is a          labeling such as an assignment of each pixel in the image to          foreground or background, or the parse tree for the sentence. Despite          marginal and MAP inference for many of these models being NP-hard in          the worst-case, approximate inference algorithms are remarkably          successful and as a result structured prediction is widely used.                     What makes these real-world instances different from worst-case          instances? One key difference is that in all of these applications,          there is an underlying \"ground truth\" which structured prediction is          aiming to find. In this talk, I will introduce a new theoretical          framework for analyzing structured prediction algorithms in terms of          their ability to achieve small Hamming error. We study the          computational and statistical trade-offs that arise in this setting,          and illustrate a setting where polynomial-time algorithms can perform          optimal prediction, despite the corresponding MAP inference task being          NP-hard.                     Joint work with Amir Globerson, Tim Roughgarden, and Cafer Yildirim.                                       List of previous talks                                                  Friday January 30         2:15PM         WWH 1314                                                         Michael Kapralov (IBM Watson)                                         Sample-Optimal Fourier Sampling in Any Constant Dimension                                [+]                                           Abstract: We present an algorithm that computes a k-sparse approximation to any signal from O(k\\log N) Fourier measurements of a length N signal. This matches the known lower bound of O(k \\log(N/k)) up to constant factors for any k\\leq N^{1-\\delta}. The algorithm runs in near-linear time, and provides the so-called \\ell_2/\\ell_2 guarantee. Our algorithm extends to higher dimensions, leading to sample complexity of O_d(k\\log N), which is again optimal up to constant factors for any constant d. This is the first sample optimal algorithm for these problems.   Using similar techniques, we also obtain an algorithm with slightly suboptimal sample complexity O(k\\log N (\\log\\log N)^2) and a sub-linear time O(k \\log^{O(1)} N) for any constant d. This generalizes the result of [IKP] to higher dimensions.   We also present preliminary experimental evaluation of our sample-optimal near-linear time algorithm, indicating that the empirical sampling complexity of the algorithm is comparable to that of other recovery methods known in the literature, while providing strong provable guarantees on the recovery quality.   (joint work with Piotr Indyk)                                                                            Friday February 6         2:15PM         WWH 1314                                                         Ofer Shayevitz (Tel Aviv University)                                         An Upper Bound on the Sizes of Multiset-Union-Free Families                                [+]                                           Abstract: Two families of subsets of [n] are called multiset-union-free          if all their pairwise multiset unions are distinct. Despite much effort          over the years, not much is known on the largest possible sizes of such families,          and a wide gap remains between the best known constructions and upper bounds.          In this work we derive a new upper bound on the sizes of families that possess this property,          improving a result by Urbanke and Li. To that end, we introduce a soft variation of the          Sauer-Perles-Shelah Lemma, that is then used in conjunction with an information-theoretic           argument for a more general setup.   Joint work with Or Ordentlich.                                                                             Friday February 13         2:15PM         WWH 1314                                                         Elliot Anshelevich (RPI)                                         Stable Matching, Friendship, and Altruism                                [+]                                           Abstract: We will discuss both integral and fractional versions of \"correlated stable matching\"          problems. Each player is a node in a social network and strives to form a good match with a          neighboring player; the player utilities from forming a match are correlated. We consider          the existence, computation, and inefficiency of stable matchings from which no pair of players          wants to deviate. We especially focus on networks where players are embedded in a social context,          and may incorporate friendship relations or altruism into their decisions.                     When the benefits from a match are the same for both players, we show that incorporating the          well-being of other players into their matching decisions significantly decreases the price of          stability, while the price of anarchy remains unaffected. Furthermore, a good stable matching          achieving the price of stability bound always exists and can be reached in polynomial time. We          extend these results to more general matching rewards, when players matched to each other may          receive different utilities from the match. For this more general case, we show that incorporating          social context (i.e., \"caring about your friends\") can make an even larger difference, and greatly          reduce the price of anarchy. Finally, we extend most of our results to network contribution games,          in which players can decide how much effort to contribute to each incident edge, instead of simply          choosing a single node to match with.                                                                             Friday March 13         2:15PM         WWH 1314                                                         Justin Thaler (Yahoo! Labs)                                         Approximate Degree and the Method of Dual Polynomials                                [+]                                           Abstract: The \\eps-approximate degree of a Boolean function is the minimum degree of a real polynomial that          point-wise approximates f to error \\eps. Approximate degree has wide-ranging applications in theoretical computer science,          from computational learning theory to communication, query, and circuit complexity. Despite its importance,          our understanding of approximate degree remains somewhat limited, with few general results known.                      The focus of this talk will be on a relatively new method for proving lower bounds on approximate degree:          specifying \\emph{dual polynomials}, which are dual solutions to a certain linear program capturing the          approximate degree of any function. After surveying earlier work on approximate degree, I will describe          how the method of dual polynomials has recently enabled progress on several open problems.                     Based on joint work with Mark Bun                                                                              Friday March 27         2:15PM         WWH 1314                                                         Michael Forbes (IAS)                                         Dimension Expanders via Rank Condensers                                [+]                                           Abstract: Expander graphs are sparse graphs with good connectivity properties and they have           become ubiquitous in theoretical computer science. Dimension expanders are a linear-algebraic          variant where we ask for a constant number of linear maps that expand subspaces of a vector space          (instead of subsets of vertices). After their definition 10 years ago by Barak, Impagliazzo, Shpilka          and Wigderson there are now two constructions of constant-degree dimension expanders, both of which          suggest dimension expanders are more complicated than expander graphs.                     In this work, we give a new construction of constant-degree dimension expanders (over large fields)          which is quite simple. It follows from an emerging theory of linear-algebraic pseudorandomness where          the rank of a subspace plays the role of the min-entropy of a random variable. In particular, we use          the recent near-optimal construction of subspace designs by Guruswami and Kopparty (based on Wronskians)          to construct a near optimal \"lossy rank condenser\". This condenser, in addition to a tensoring operation,          yields the desired dimension expanders.                     Joint work with Venkatesan Guruswami                                              If you would like to present something, please send an email to: igor (dot) shinkar (at) nyu (dot) edu   To subscribe to the mailing list, see: www.cs.nyu.edu/mailman/listinfo/cs_theory_seminar/                           Schedule of past talks:                         Fall 2007      Spring 2008      Fall 2008      Spring 2009      Fall 2009      Spring 2010           Fall 2010      Spring 2012      Fall 2012      Spring 2013      Fall 2013      Spring 2014      Fall 2014"}]},
{"detail": [{"content": "NYU/Courant Theory Seminar                 NYU CS Theory Seminar                              Usual coordinates:     Friday, 2:15PM    Room 1314    Warren Weaver Hall    251 Mercer Street                  Spring 2015 Schedule       Upcoming talks                                                       Thursday April 16         3:00PM         WWH 201                                                         Ankur Moitra (MIT)                                          Tensor Prediction, Rademacher Complexity and Random 3-XOR                                [+]                                           Abstract: Here we study the tensor prediction problem, where the goal is to accurately predict the entries of a low rank,          third-order tensor (with noise) given as few observations as possible. We give algorithms based on the sixth level of the          sum-of-squares hierarchy that work with roughly m = n^3/2 observations, and we complement our result by showing that any          attempt to solve tensor prediction with fewer observations through the sum-of-squares hierarchy would run in moderately          exponential time. In contrast, information theoretically roughly m = n observations suffice.                     This work is part of a broader agenda of studying computational vs. statistical tradeoffs through the sum-of-squares hierarchy.          In particular, for linear inverse problems (such as tensor prediction) the natural sum-of-squares relaxation gives rise to a          sequence of norms. Our approach is to characterize their Rademacher complexity. Moreover, both our upper and lower bounds are          based on connections between this, and the task of strongly refuting random 3-XOR formulas, and the resolution proof system.                     This talk is based on joint work with Boaz Barak                                                                               Friday April 24         2:15PM         WWH 1314                                                         Yuval Filmus (IAS)                                         On the Coppersmith-Winograd approach to matrix multiplication                                [+]                                           Abstract:          Ever since Strassen's O(n^{2.81}) matrix multiplication algorithm stunned the mathematical community,          the quest for fast matrix multiplication algorithms has been a holy grail in computer science.          At first progress was fast, culminating in Coppersmith and Winograd's O(n^{2.376}) algorithm of 1987.          Recently interest in the area has reawakened due to work of Stothers, Vassilevska-Williams and Le Gall,          who managed to improve the exponent slightly from 2.376 to 2.373.                     Roughly speaking, Coppersmith and Winograd constructed an edifice turning an \"identity\"          (some kind of mathematical object) into a fast matrix multiplication algorithm.          Applying their method on the identity TCW, they obtained an O(n^{2.388}) algorithm.          Applying it to TCW^2 (identities can be squared!), they obtained their O(n^{2.376}) algorithm.          They stopped there since computing was a lot more cumbersome in the 1980s.          Using modern computers, Stothers, Vassilevska-Williams and Le Gall were able to analyze          higher powers of TCW (up to TCW^32), and so reduced the exponent to 2.373.                     Our talk answers the following question:                      What is the limit of this approach?                                 We show that this approach cannot yield an exponent smaller than 2.372.          No prior knowledge will be assumed.                     Joint work with Andris Ambainis (University of Latvia) and Francois Le Gall (University of Tokyo).                                                                               Friday May 1         2:15PM         WWH 1314                                                         Ilya Razenshteyn (MIT)                                         TBD                                [+]                                           Abstract: TBD                                                                             Friday May 8         2:15PM         WWH 1314                                                         David Sontag (NYU)                                         How Good Is Structured Prediction?                                [+]                                           Abstract: Many machine learning tasks can be posed as structured prediction,          where the goal is to predict a labeling or structured object. For          example, the input may be an image or a sentence, and the output is a          labeling such as an assignment of each pixel in the image to          foreground or background, or the parse tree for the sentence. Despite          marginal and MAP inference for many of these models being NP-hard in          the worst-case, approximate inference algorithms are remarkably          successful and as a result structured prediction is widely used.                     What makes these real-world instances different from worst-case          instances? One key difference is that in all of these applications,          there is an underlying \"ground truth\" which structured prediction is          aiming to find. In this talk, I will introduce a new theoretical          framework for analyzing structured prediction algorithms in terms of          their ability to achieve small Hamming error. We study the          computational and statistical trade-offs that arise in this setting,          and illustrate a setting where polynomial-time algorithms can perform          optimal prediction, despite the corresponding MAP inference task being          NP-hard.                     Joint work with Amir Globerson, Tim Roughgarden, and Cafer Yildirim.                                       List of previous talks                                                  Friday January 30         2:15PM         WWH 1314                                                         Michael Kapralov (IBM Watson)                                         Sample-Optimal Fourier Sampling in Any Constant Dimension                                [+]                                           Abstract: We present an algorithm that computes a k-sparse approximation to any signal from O(k\\log N) Fourier measurements of a length N signal. This matches the known lower bound of O(k \\log(N/k)) up to constant factors for any k\\leq N^{1-\\delta}. The algorithm runs in near-linear time, and provides the so-called \\ell_2/\\ell_2 guarantee. Our algorithm extends to higher dimensions, leading to sample complexity of O_d(k\\log N), which is again optimal up to constant factors for any constant d. This is the first sample optimal algorithm for these problems.   Using similar techniques, we also obtain an algorithm with slightly suboptimal sample complexity O(k\\log N (\\log\\log N)^2) and a sub-linear time O(k \\log^{O(1)} N) for any constant d. This generalizes the result of [IKP] to higher dimensions.   We also present preliminary experimental evaluation of our sample-optimal near-linear time algorithm, indicating that the empirical sampling complexity of the algorithm is comparable to that of other recovery methods known in the literature, while providing strong provable guarantees on the recovery quality.   (joint work with Piotr Indyk)                                                                            Friday February 6         2:15PM         WWH 1314                                                         Ofer Shayevitz (Tel Aviv University)                                         An Upper Bound on the Sizes of Multiset-Union-Free Families                                [+]                                           Abstract: Two families of subsets of [n] are called multiset-union-free          if all their pairwise multiset unions are distinct. Despite much effort          over the years, not much is known on the largest possible sizes of such families,          and a wide gap remains between the best known constructions and upper bounds.          In this work we derive a new upper bound on the sizes of families that possess this property,          improving a result by Urbanke and Li. To that end, we introduce a soft variation of the          Sauer-Perles-Shelah Lemma, that is then used in conjunction with an information-theoretic           argument for a more general setup.   Joint work with Or Ordentlich.                                                                             Friday February 13         2:15PM         WWH 1314                                                         Elliot Anshelevich (RPI)                                         Stable Matching, Friendship, and Altruism                                [+]                                           Abstract: We will discuss both integral and fractional versions of \"correlated stable matching\"          problems. Each player is a node in a social network and strives to form a good match with a          neighboring player; the player utilities from forming a match are correlated. We consider          the existence, computation, and inefficiency of stable matchings from which no pair of players          wants to deviate. We especially focus on networks where players are embedded in a social context,          and may incorporate friendship relations or altruism into their decisions.                     When the benefits from a match are the same for both players, we show that incorporating the          well-being of other players into their matching decisions significantly decreases the price of          stability, while the price of anarchy remains unaffected. Furthermore, a good stable matching          achieving the price of stability bound always exists and can be reached in polynomial time. We          extend these results to more general matching rewards, when players matched to each other may          receive different utilities from the match. For this more general case, we show that incorporating          social context (i.e., \"caring about your friends\") can make an even larger difference, and greatly          reduce the price of anarchy. Finally, we extend most of our results to network contribution games,          in which players can decide how much effort to contribute to each incident edge, instead of simply          choosing a single node to match with.                                                                             Friday March 13         2:15PM         WWH 1314                                                         Justin Thaler (Yahoo! Labs)                                         Approximate Degree and the Method of Dual Polynomials                                [+]                                           Abstract: The \\eps-approximate degree of a Boolean function is the minimum degree of a real polynomial that          point-wise approximates f to error \\eps. Approximate degree has wide-ranging applications in theoretical computer science,          from computational learning theory to communication, query, and circuit complexity. Despite its importance,          our understanding of approximate degree remains somewhat limited, with few general results known.                      The focus of this talk will be on a relatively new method for proving lower bounds on approximate degree:          specifying \\emph{dual polynomials}, which are dual solutions to a certain linear program capturing the          approximate degree of any function. After surveying earlier work on approximate degree, I will describe          how the method of dual polynomials has recently enabled progress on several open problems.                     Based on joint work with Mark Bun                                                                              Friday March 27         2:15PM         WWH 1314                                                         Michael Forbes (IAS)                                         Dimension Expanders via Rank Condensers                                [+]                                           Abstract: Expander graphs are sparse graphs with good connectivity properties and they have           become ubiquitous in theoretical computer science. Dimension expanders are a linear-algebraic          variant where we ask for a constant number of linear maps that expand subspaces of a vector space          (instead of subsets of vertices). After their definition 10 years ago by Barak, Impagliazzo, Shpilka          and Wigderson there are now two constructions of constant-degree dimension expanders, both of which          suggest dimension expanders are more complicated than expander graphs.                     In this work, we give a new construction of constant-degree dimension expanders (over large fields)          which is quite simple. It follows from an emerging theory of linear-algebraic pseudorandomness where          the rank of a subspace plays the role of the min-entropy of a random variable. In particular, we use          the recent near-optimal construction of subspace designs by Guruswami and Kopparty (based on Wronskians)          to construct a near optimal \"lossy rank condenser\". This condenser, in addition to a tensoring operation,          yields the desired dimension expanders.                     Joint work with Venkatesan Guruswami                                              If you would like to present something, please send an email to: igor (dot) shinkar (at) nyu (dot) edu   To subscribe to the mailing list, see: www.cs.nyu.edu/mailman/listinfo/cs_theory_seminar/                           Schedule of past talks:                         Fall 2007      Spring 2008      Fall 2008      Spring 2009      Fall 2009      Spring 2010           Fall 2010      Spring 2012      Fall 2012      Spring 2013      Fall 2013      Spring 2014      Fall 2014"}, {"content": "Graduate Theory and History Placement Exam Information - Music and Performing Arts Professions Current Students - NYU Steinhardt                                                      Skip to content         NYU Steinhardt School of Culture, Education, and Human Development             apply now     request info     contact                                     Department of Music and Performing Arts Professions           Overview        Location     History     Director's Message     International Welcome and History           Academics        Brass Studies     Woodwind Studies     String Studies     Percussion Studies     Jazz Studies     Piano Studies     Music Theatre     Classical Voice and Opera Studies     Music Composition     Scoring for Film and Multimedia     Songwriting     Music Business     Music Technology     Music Education     Music Therapy     Dance Education     Educational Theatre     Performing Arts Administration     Drama Therapy     Summer Programs     Study Abroad     Music Minor           Admissions        Undergraduate     Graduate     Doctoral     Prospective Student Auditions           People        Faculty     Students     Alumni     Staff           Ensembles        Overview     Audition Guidelines     Audition Requirements     Online Audition Registration           Research        ArtsPraxis     Music and the Moving Image     Music and Audio Research Laboratory     Center for Research in Dance Education     Faculty Research Interests     Faculty Collaborations           Events        Facilities        Facilities     Music Technology Facilities           FAQ                 Music and Performing Arts Professions Current Students                   Incoming Students FAQ    Student Bios    Theory Placement Test Dates    Graduate/Doctoral Information    Recital Planning    Ensemble Auditions    Doctoral Candidacy                       Graduate Theory and History Placement Exam Information                     Basic competence in music history and theory is a prerequisite for all graduate degree programs in music. Entering graduate students are required to take advisory exams in both areas prior to arrival; placements will be determined by interpreting the exam results in light of a student's educational background and the degree program for which she or he is enrolled. Remedial courses cannot be used to meet degree requirements within any of the graduate programs. It is the responsibility of the student to see that deficiencies are remedied swiftly so as not to impede their progress toward the degree.    About the Advisory Exams:    Who must take them? Advisory exams are required of all entering graduate students in music, including those enrolling directly in Ph.D or Advanced Certificate programs with the following exceptions:       Students who have completed a previous music degree (undergraduate or graduate) within our department in the last five years are exempt from both exams.    Music Business students are exempt from both exams.       When are they given? Students are generally required to take both exams prior to their first semester of study. Postponement of the history exam by one semester will be granted and is recommended for all international students who have not yet passed their English Proficiency Test. Other postponements may be granted in extraordinary circumstances by the Theory Director upon the recommendation of a student's Program Director. The theory and history exams are given throughout each summer and in the week prior to the beginning of the second semester (usually the second week of January). Information about the exact dates, times, and locations for each year may be found at the Graduate Theory and History Placement Exams upcoming test dates page.  What is the format and content of the exams? In music theory and aural skills, students must demonstrate mastery of fundamentals as well as proficiency in part writing, directed analysis of tonal music, and various kinds of dictation (melodic, rhythmic, harmonic). The exam lasts approximately two and a half hours. In music history, students must demonstrate knowledge of the major historical periods, styles, composers and genres throughout the history of Western art music as well as a familiarity with the broad spectrum of music in the twentieth (and twenty-first) century. It consists of a written part and a listening part, lasting in total approximately two and a half hours. The written part involves matching, multiple choice, and short answer. The listening part similarly involves simple identification (via multiple choice) of the periods and composers of prominent works.  How can students prepare for them?    Students can review successfully in a variety of ways. Students with good preparation in their undergraduate programs might review materials and texts from their undergraduate courses. Also recommended are any of the major comprehensive texts in either area. In particular, we recommend the sources below. For theory, either of the following:    Laitz, Steven and Christopher Bartlette. Graduate Review of Tonal Theory: A Recasting of Common Practice Harmony, Form and Counterpoint. (New York: Oxford University Press, 2010).    Aldwell, Edward and Carl Schachter. Harmony and Voice Leading, 3rd ed. (New York: Schirmer, 2002)    For music history, both of the following:    Burkholder, J. Peter, Grout, Donald J. and Claude Palisca. A History of Western Music, 8th ed. (New York: W. W. Norton, 2010).    Burkholder, J. Peter, and Claude Palisca. Norton Anthology of Western Music , 6th ed. (New York: W. W. Norton, 2010)    The students may also find helpful the following music history review aid:    Poultney, David. Studying Music History: Learning, Reasoning, and Writing about Music History and Literature , 2nd ed. (Saddle River: Prentice Hall, 1995)    Do students need to sign up for the exams in advance? No.  May students take the exam more than once? No.  May students take remedial courses instead of the exam, or in preparation for them? No.    About the Remediation:    How is remediation handled? On the basis of the exam results, some students are exempted from all remedial requirements. Many students, however, may be required to take one or more courses in music theory, aural comprehension, and/or music history. The Directory of Music Theory will assign specific course requirements for those students in need of remediation. These requirements must be satisfied prior to graduation. May students write papers or do other independent projects instead of taking the required remedial courses? No.  Who might I speak with for further information? Professor Panayotis Mavromatis, Director of Music Theory Professor Sarah Marlowe, Associate Director of Music Theory smusic.theory@nyu.edu                 Department of Music and Performing Arts Professions - 35 W. 4th Street, Suite 1077 -  New York, NY 10012 -  212 998 5424    This site, and all its contents, are Copyright &copy;    by New York University. All rights reserved."}]},
{"detail": [{"content": "NYU/Courant Theory Seminar                 NYU CS Theory Seminar                              Usual coordinates:     Friday, 2:15PM    Room 1314    Warren Weaver Hall    251 Mercer Street                  Spring 2015 Schedule       Upcoming talks                                                       Thursday April 16         3:00PM         WWH 201                                                         Ankur Moitra (MIT)                                          Tensor Prediction, Rademacher Complexity and Random 3-XOR                                [+]                                           Abstract: Here we study the tensor prediction problem, where the goal is to accurately predict the entries of a low rank,          third-order tensor (with noise) given as few observations as possible. We give algorithms based on the sixth level of the          sum-of-squares hierarchy that work with roughly m = n^3/2 observations, and we complement our result by showing that any          attempt to solve tensor prediction with fewer observations through the sum-of-squares hierarchy would run in moderately          exponential time. In contrast, information theoretically roughly m = n observations suffice.                     This work is part of a broader agenda of studying computational vs. statistical tradeoffs through the sum-of-squares hierarchy.          In particular, for linear inverse problems (such as tensor prediction) the natural sum-of-squares relaxation gives rise to a          sequence of norms. Our approach is to characterize their Rademacher complexity. Moreover, both our upper and lower bounds are          based on connections between this, and the task of strongly refuting random 3-XOR formulas, and the resolution proof system.                     This talk is based on joint work with Boaz Barak                                                                               Friday April 24         2:15PM         WWH 1314                                                         Yuval Filmus (IAS)                                         On the Coppersmith-Winograd approach to matrix multiplication                                [+]                                           Abstract:          Ever since Strassen's O(n^{2.81}) matrix multiplication algorithm stunned the mathematical community,          the quest for fast matrix multiplication algorithms has been a holy grail in computer science.          At first progress was fast, culminating in Coppersmith and Winograd's O(n^{2.376}) algorithm of 1987.          Recently interest in the area has reawakened due to work of Stothers, Vassilevska-Williams and Le Gall,          who managed to improve the exponent slightly from 2.376 to 2.373.                     Roughly speaking, Coppersmith and Winograd constructed an edifice turning an \"identity\"          (some kind of mathematical object) into a fast matrix multiplication algorithm.          Applying their method on the identity TCW, they obtained an O(n^{2.388}) algorithm.          Applying it to TCW^2 (identities can be squared!), they obtained their O(n^{2.376}) algorithm.          They stopped there since computing was a lot more cumbersome in the 1980s.          Using modern computers, Stothers, Vassilevska-Williams and Le Gall were able to analyze          higher powers of TCW (up to TCW^32), and so reduced the exponent to 2.373.                     Our talk answers the following question:                      What is the limit of this approach?                                 We show that this approach cannot yield an exponent smaller than 2.372.          No prior knowledge will be assumed.                     Joint work with Andris Ambainis (University of Latvia) and Francois Le Gall (University of Tokyo).                                                                               Friday May 1         2:15PM         WWH 1314                                                         Ilya Razenshteyn (MIT)                                         TBD                                [+]                                           Abstract: TBD                                                                             Friday May 8         2:15PM         WWH 1314                                                         David Sontag (NYU)                                         How Good Is Structured Prediction?                                [+]                                           Abstract: Many machine learning tasks can be posed as structured prediction,          where the goal is to predict a labeling or structured object. For          example, the input may be an image or a sentence, and the output is a          labeling such as an assignment of each pixel in the image to          foreground or background, or the parse tree for the sentence. Despite          marginal and MAP inference for many of these models being NP-hard in          the worst-case, approximate inference algorithms are remarkably          successful and as a result structured prediction is widely used.                     What makes these real-world instances different from worst-case          instances? One key difference is that in all of these applications,          there is an underlying \"ground truth\" which structured prediction is          aiming to find. In this talk, I will introduce a new theoretical          framework for analyzing structured prediction algorithms in terms of          their ability to achieve small Hamming error. We study the          computational and statistical trade-offs that arise in this setting,          and illustrate a setting where polynomial-time algorithms can perform          optimal prediction, despite the corresponding MAP inference task being          NP-hard.                     Joint work with Amir Globerson, Tim Roughgarden, and Cafer Yildirim.                                       List of previous talks                                                  Friday January 30         2:15PM         WWH 1314                                                         Michael Kapralov (IBM Watson)                                         Sample-Optimal Fourier Sampling in Any Constant Dimension                                [+]                                           Abstract: We present an algorithm that computes a k-sparse approximation to any signal from O(k\\log N) Fourier measurements of a length N signal. This matches the known lower bound of O(k \\log(N/k)) up to constant factors for any k\\leq N^{1-\\delta}. The algorithm runs in near-linear time, and provides the so-called \\ell_2/\\ell_2 guarantee. Our algorithm extends to higher dimensions, leading to sample complexity of O_d(k\\log N), which is again optimal up to constant factors for any constant d. This is the first sample optimal algorithm for these problems.   Using similar techniques, we also obtain an algorithm with slightly suboptimal sample complexity O(k\\log N (\\log\\log N)^2) and a sub-linear time O(k \\log^{O(1)} N) for any constant d. This generalizes the result of [IKP] to higher dimensions.   We also present preliminary experimental evaluation of our sample-optimal near-linear time algorithm, indicating that the empirical sampling complexity of the algorithm is comparable to that of other recovery methods known in the literature, while providing strong provable guarantees on the recovery quality.   (joint work with Piotr Indyk)                                                                            Friday February 6         2:15PM         WWH 1314                                                         Ofer Shayevitz (Tel Aviv University)                                         An Upper Bound on the Sizes of Multiset-Union-Free Families                                [+]                                           Abstract: Two families of subsets of [n] are called multiset-union-free          if all their pairwise multiset unions are distinct. Despite much effort          over the years, not much is known on the largest possible sizes of such families,          and a wide gap remains between the best known constructions and upper bounds.          In this work we derive a new upper bound on the sizes of families that possess this property,          improving a result by Urbanke and Li. To that end, we introduce a soft variation of the          Sauer-Perles-Shelah Lemma, that is then used in conjunction with an information-theoretic           argument for a more general setup.   Joint work with Or Ordentlich.                                                                             Friday February 13         2:15PM         WWH 1314                                                         Elliot Anshelevich (RPI)                                         Stable Matching, Friendship, and Altruism                                [+]                                           Abstract: We will discuss both integral and fractional versions of \"correlated stable matching\"          problems. Each player is a node in a social network and strives to form a good match with a          neighboring player; the player utilities from forming a match are correlated. We consider          the existence, computation, and inefficiency of stable matchings from which no pair of players          wants to deviate. We especially focus on networks where players are embedded in a social context,          and may incorporate friendship relations or altruism into their decisions.                     When the benefits from a match are the same for both players, we show that incorporating the          well-being of other players into their matching decisions significantly decreases the price of          stability, while the price of anarchy remains unaffected. Furthermore, a good stable matching          achieving the price of stability bound always exists and can be reached in polynomial time. We          extend these results to more general matching rewards, when players matched to each other may          receive different utilities from the match. For this more general case, we show that incorporating          social context (i.e., \"caring about your friends\") can make an even larger difference, and greatly          reduce the price of anarchy. Finally, we extend most of our results to network contribution games,          in which players can decide how much effort to contribute to each incident edge, instead of simply          choosing a single node to match with.                                                                             Friday March 13         2:15PM         WWH 1314                                                         Justin Thaler (Yahoo! Labs)                                         Approximate Degree and the Method of Dual Polynomials                                [+]                                           Abstract: The \\eps-approximate degree of a Boolean function is the minimum degree of a real polynomial that          point-wise approximates f to error \\eps. Approximate degree has wide-ranging applications in theoretical computer science,          from computational learning theory to communication, query, and circuit complexity. Despite its importance,          our understanding of approximate degree remains somewhat limited, with few general results known.                      The focus of this talk will be on a relatively new method for proving lower bounds on approximate degree:          specifying \\emph{dual polynomials}, which are dual solutions to a certain linear program capturing the          approximate degree of any function. After surveying earlier work on approximate degree, I will describe          how the method of dual polynomials has recently enabled progress on several open problems.                     Based on joint work with Mark Bun                                                                              Friday March 27         2:15PM         WWH 1314                                                         Michael Forbes (IAS)                                         Dimension Expanders via Rank Condensers                                [+]                                           Abstract: Expander graphs are sparse graphs with good connectivity properties and they have           become ubiquitous in theoretical computer science. Dimension expanders are a linear-algebraic          variant where we ask for a constant number of linear maps that expand subspaces of a vector space          (instead of subsets of vertices). After their definition 10 years ago by Barak, Impagliazzo, Shpilka          and Wigderson there are now two constructions of constant-degree dimension expanders, both of which          suggest dimension expanders are more complicated than expander graphs.                     In this work, we give a new construction of constant-degree dimension expanders (over large fields)          which is quite simple. It follows from an emerging theory of linear-algebraic pseudorandomness where          the rank of a subspace plays the role of the min-entropy of a random variable. In particular, we use          the recent near-optimal construction of subspace designs by Guruswami and Kopparty (based on Wronskians)          to construct a near optimal \"lossy rank condenser\". This condenser, in addition to a tensoring operation,          yields the desired dimension expanders.                     Joint work with Venkatesan Guruswami                                              If you would like to present something, please send an email to: igor (dot) shinkar (at) nyu (dot) edu   To subscribe to the mailing list, see: www.cs.nyu.edu/mailman/listinfo/cs_theory_seminar/                           Schedule of past talks:                         Fall 2007      Spring 2008      Fall 2008      Spring 2009      Fall 2009      Spring 2010           Fall 2010      Spring 2012      Fall 2012      Spring 2013      Fall 2013      Spring 2014      Fall 2014"}, {"content": "Graduate Theory and History Placement Exam Information - Music and Performing Arts Professions Current Students - NYU Steinhardt                                                      Skip to content         NYU Steinhardt School of Culture, Education, and Human Development             apply now     request info     contact                                     Department of Music and Performing Arts Professions           Overview        Location     History     Director's Message     International Welcome and History           Academics        Brass Studies     Woodwind Studies     String Studies     Percussion Studies     Jazz Studies     Piano Studies     Music Theatre     Classical Voice and Opera Studies     Music Composition     Scoring for Film and Multimedia     Songwriting     Music Business     Music Technology     Music Education     Music Therapy     Dance Education     Educational Theatre     Performing Arts Administration     Drama Therapy     Summer Programs     Study Abroad     Music Minor           Admissions        Undergraduate     Graduate     Doctoral     Prospective Student Auditions           People        Faculty     Students     Alumni     Staff           Ensembles        Overview     Audition Guidelines     Audition Requirements     Online Audition Registration           Research        ArtsPraxis     Music and the Moving Image     Music and Audio Research Laboratory     Center for Research in Dance Education     Faculty Research Interests     Faculty Collaborations           Events        Facilities        Facilities     Music Technology Facilities           FAQ                 Music and Performing Arts Professions Current Students                   Incoming Students FAQ    Student Bios    Theory Placement Test Dates    Graduate/Doctoral Information    Recital Planning    Ensemble Auditions    Doctoral Candidacy                       Graduate Theory and History Placement Exam Information                     Basic competence in music history and theory is a prerequisite for all graduate degree programs in music. Entering graduate students are required to take advisory exams in both areas prior to arrival; placements will be determined by interpreting the exam results in light of a student's educational background and the degree program for which she or he is enrolled. Remedial courses cannot be used to meet degree requirements within any of the graduate programs. It is the responsibility of the student to see that deficiencies are remedied swiftly so as not to impede their progress toward the degree.    About the Advisory Exams:    Who must take them? Advisory exams are required of all entering graduate students in music, including those enrolling directly in Ph.D or Advanced Certificate programs with the following exceptions:       Students who have completed a previous music degree (undergraduate or graduate) within our department in the last five years are exempt from both exams.    Music Business students are exempt from both exams.       When are they given? Students are generally required to take both exams prior to their first semester of study. Postponement of the history exam by one semester will be granted and is recommended for all international students who have not yet passed their English Proficiency Test. Other postponements may be granted in extraordinary circumstances by the Theory Director upon the recommendation of a student's Program Director. The theory and history exams are given throughout each summer and in the week prior to the beginning of the second semester (usually the second week of January). Information about the exact dates, times, and locations for each year may be found at the Graduate Theory and History Placement Exams upcoming test dates page.  What is the format and content of the exams? In music theory and aural skills, students must demonstrate mastery of fundamentals as well as proficiency in part writing, directed analysis of tonal music, and various kinds of dictation (melodic, rhythmic, harmonic). The exam lasts approximately two and a half hours. In music history, students must demonstrate knowledge of the major historical periods, styles, composers and genres throughout the history of Western art music as well as a familiarity with the broad spectrum of music in the twentieth (and twenty-first) century. It consists of a written part and a listening part, lasting in total approximately two and a half hours. The written part involves matching, multiple choice, and short answer. The listening part similarly involves simple identification (via multiple choice) of the periods and composers of prominent works.  How can students prepare for them?    Students can review successfully in a variety of ways. Students with good preparation in their undergraduate programs might review materials and texts from their undergraduate courses. Also recommended are any of the major comprehensive texts in either area. In particular, we recommend the sources below. For theory, either of the following:    Laitz, Steven and Christopher Bartlette. Graduate Review of Tonal Theory: A Recasting of Common Practice Harmony, Form and Counterpoint. (New York: Oxford University Press, 2010).    Aldwell, Edward and Carl Schachter. Harmony and Voice Leading, 3rd ed. (New York: Schirmer, 2002)    For music history, both of the following:    Burkholder, J. Peter, Grout, Donald J. and Claude Palisca. A History of Western Music, 8th ed. (New York: W. W. Norton, 2010).    Burkholder, J. Peter, and Claude Palisca. Norton Anthology of Western Music , 6th ed. (New York: W. W. Norton, 2010)    The students may also find helpful the following music history review aid:    Poultney, David. Studying Music History: Learning, Reasoning, and Writing about Music History and Literature , 2nd ed. (Saddle River: Prentice Hall, 1995)    Do students need to sign up for the exams in advance? No.  May students take the exam more than once? No.  May students take remedial courses instead of the exam, or in preparation for them? No.    About the Remediation:    How is remediation handled? On the basis of the exam results, some students are exempted from all remedial requirements. Many students, however, may be required to take one or more courses in music theory, aural comprehension, and/or music history. The Directory of Music Theory will assign specific course requirements for those students in need of remediation. These requirements must be satisfied prior to graduation. May students write papers or do other independent projects instead of taking the required remedial courses? No.  Who might I speak with for further information? Professor Panayotis Mavromatis, Director of Music Theory Professor Sarah Marlowe, Associate Director of Music Theory smusic.theory@nyu.edu                 Department of Music and Performing Arts Professions - 35 W. 4th Street, Suite 1077 -  New York, NY 10012 -  212 998 5424    This site, and all its contents, are Copyright &copy;    by New York University. All rights reserved."}, {"content": "NYU Computer Science Department &gt; Algorithms and Theory                                                                                                                                 Search                                                  go                         Location          Contacts      Directions      NYC Information            Admissions          Undergraduate Admissions      Graduate Admissions           People           Faculty        Researchers/Visitors      Administration/Staff      Students: PhD / MS      Alumni / In Memoriam             Research           Research Areas      Tech Reports      Theses: PhD / MS        Faculty Recognition      Student Recognition           Education           Undergraduate Program      Graduate Program : PhD / MS        Courses      Office Hours           News / Events           Colloquia        Calendar: Grad / Undergrad           Job Openings           Faculty Positions             Links           Libraries      Student Organizations      CIMS Computing                                                                                                                                                                               Algorithms and Theory   Edit Title                Edit Body      Faculty    Richard Cole  Yevgeniy Dodis  Subhash Khot  Bud Mishra  Mehryar Mohri  Assaf Naor  Oded Regev  Victor Shoup  Alan R. Siegel  Joel H. Spencer  Chee K. Yap     Three key issues for an algorithm are: Is it correct? How efficient is it? Can one do better? Our strong and diverse group seeks provable answers to these questions. It focuses on problems and questions in the following areas: computational geometry, computational algebra, randomness (in algorithm design and average case analysis), computational biology, correctness of programs and hardware, and game theory.    Richard Cole has worked on a wide range of algorithmic topics. His current focus is the new area of algorithmic economics. One of the fundamental notions in economics is the concept of equilibrium: for example, prices that approximately balance supply and demand are expected to be the norm. From a computer science perspective, for an equilibrium to be attainable, it has to be computationally feasible to find equilibrium prices and, in addition, the market itself must be able to \"compute\" such prices. Prof. Cole, his collaborators, and students are studying the computational hardness of the pricing problem and specific pricing algorithms for different market and agent models.    Yevgeniy Dodis is primarily interested in cryptography. His current primary research directions are cryptography based on imperfect randomness, exposure-resilient cryptography, cryptography with biometrics and other noisy data, hash functions and random oracle model and information-theoretic cryptography. Recent achievements include design of special purpose randomness extractors for imperfect sources, formal model of cryptography based on noisy data, design and formalization of intrusion-resilient cryptosystems and new criteria and techniques for design of hash functions.    Subhash Khot is broadly interested in all aspects of algorithms and computational complexity. His specific interests include efficiently computing approximate solutions to NP-hard problems and negative results showing that for many problems, even computing approximate solutions is intractable. His recent works include negative results for semi-definite programming based algorithms, their connection to metric geometry and analysis, and negative results for some learning theory problems.    Bud Mishra has worked in many areas of Computer Science. His current focus is on applications of computer science and mathematical ideas to biological sciences. He has developed optical mapping technology, a successful approach to physical genome mapping. He aims to develop efficient practical algorithmic tools for genome mapping and sequencing. He leads a number of projects in bioinformatics, primarily in genomics and systems biology, including a novel technology aimed at making fast and cheap sequencing of the human genome broadly accessible, a cancer genome atlas, algebraic model checking for systems biology, large-scale models of pandemic flu and smallpox and many others.    Mehryar Mohri's primary research areas are machine learning, theory and algorithms, text and speech processing, and computational biology. This includes in particular the study of the theoretical aspects of machine learning, the design of general and accurate learning algorithms, and their applications to large-scale learning problems such as those found in bioinformatics and language processing.    Oded Regev's research is in mathematical aspects of theoretical computer science. He is particularly interested in advancing the area of lattice-based cryptography using concepts from quantum computation, analysis, and number theory.    Victor Shoup 's research areas are cryptography and computational number theory; he is especially interested in the interactions between these two areas. He designs and analyzes cryptographic primitives and protocols with security properties that can be proven based on clear and reasonable assumptions, and which are nevertheless practical enough to use in the real world. Most recently, he has been working on practical secure deniable protocols (i.e., participants in an exchange using this protocol can deny that it ever took place) based on novel and use of number-theoretic algorithms.    Alan Siegel is interested in the analysis of algorithms and related mathematics, which includes applications from probability, statistics, partial and ordinary differential equations and methods in asymptotic analysis. He works on analysis of probabilistic processes and geometric arrangements of lines. His current research focuses on hashing functions and their properties. He is also interested in K-12 mathematics education and new approaches to teaching algorithms at the college and graduate level.    Joel Spencer is interested in applications of probabilistic methods in discrete mathematics and theoretical computer science. He worked on many topics including Ramsey theory (which studies the conditions under which order must appear in random systems), discrepancy theory (which deals with measuring irregularities of discrete distributions), random graphs and their connections to logic and randomized greedy methods. He is the author of a number of widely known books on probabilistic method.    Chee Yap works in the areas of computational geometry, algebraic computation and visualization. His current research focuses on two themes: exact arithmetic computation and large-scale visualization. Numerical nonrobustness has been called \"computer scientists' dirty secret\" --everyone knows that our numerical software can break, but we rarely talk about it. The most successful approach to solving the robustness problem in geometry is based on exact geometric computation. Chee Yap and his group are developing techniques for this type of computation based on algebraic zero bounds. Exact geometric computation provides considerable insight into the theory of real computation. The other direction of Chee Yap's work is large-scale visualization, dynamic visualization of geospatial data in particular.    Related Web Pages    Exact geometric computation  Analysis of Computer Systems Group  Geometry seminar  Theory seminar         Edit All                   top | contact webmaster"}]}]