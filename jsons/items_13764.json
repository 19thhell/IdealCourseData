[{"detail": [{"content": "NYU Depth V2 &laquo; Nathan Silberman                 Nathan Silberman                  NYU Depth Dataset V2     Nathan Silberman ,  Pushmeet Kohli ,  Derek Hoiem ,  Rob Fergus         If you use the dataset, please cite the following work:   Indoor Segmentation and Support Inference from RGBD Images  ECCV 2012  [PDF] [Bib]         Samples of the RGB image, the raw depth image, and the class labels from the dataset.       Overview   The NYU-Depth V2 data set is comprised of video sequences from a variety of indoor scenes as recorded by both the RGB and Depth cameras from the Microsoft Kinect . It features:      1449 densely labeled pairs of aligned RGB and depth images   464 new scenes taken from 3 cities   407,024 new unlabeled frames   Each object is labeled with a class and an instance number (cup1, cup2, cup3, etc)      The dataset has several components:     Labeled: A subset of the video data accompanied by dense multi-class labels. This data has also been preprocessed to fill in missing depth labels.   Raw: The raw rgb, depth and accelerometer data as provided by the Kinect.   Toolbox: Useful functions for manipulating the data and labels.      Downloads        Labeled dataset (~2.8 GB)        Raw dataset, Single File (~428 GB)        Raw dataset, Multi-part (~428 GB)        Toolbox        Labeled Dataset       Output from the RGB camera (left), preprocessed depth (center) and a set of labels (right) for the image.   The labeled dataset is a subset of the Raw Dataset. It is comprised of pairs of RGB and Depth frames that have been synchronized and annotated with dense labels for every image. In addition to the projected depth maps, we have included a set of preprocessed depth maps whose missing values have been filled in using the colorization scheme of Levin et al . Unlike, the Raw dataset, the labeled dataset is provided as a Matlab .mat file with the following variables:     accelData &#8211; Nx4 matrix of accelerometer values indicated when each frame was taken. The columns contain the roll, yaw, pitch and tilt angle of the device.   depths &#8211; HxWxN matrix of in-painted depth maps where H and W are the height and width, respectively and N is the number of images. The values of the depth elements are in meters.   images &#8211; HxWx3xN matrix of RGB images where H and W are the height and width, respectively, and N is the number of images.   instances &#8211; HxWxN matrix of instance maps. Use get_instance_masks.m in the Toolbox to recover masks for each object instance in a scene.   labels &#8211; HxWxN matrix of object label masks where H and W are the height and width, respectively and N is the number of images. The labels range from 1..C where C is the total number of classes. If a pixel&#8217;s label value is 0, then that pixel is &#8216;unlabeled&#8217;.   names &#8211; Cx1 cell array of the english names of each class.   namesToIds &#8211; map from english label names to class IDs (with C key-value pairs)   rawDepths &#8211; HxWxN matrix of raw depth maps where H and W are the height and width, respectively, and N is the number of images. These depth maps capture the depth images after they have been projected onto the RGB image plane but before the missing depth values have been filled in. Additionally, the depth non-linearity from the Kinect device has been removed and the values of each depth image are in meters.   rawDepthFilenames &#8211; Nx1 cell array of the filenames (in the Raw dataset) that were used for each of the depth images in the labeled dataset.   rawRgbFilenames &#8211; Nx1 cell array of the filenames (in the Raw dataset) that were used for each of the RGB images in the labeled dataset.   scenes &#8211; Nx1 cell array of the name of the scene from which each image was taken.   sceneTypes &#8211; Nx1 cell array of the scene type from which each image was taken.     Raw Dataset        Output from the RGB camera (left) and depth camera (right). Missing values in the depth image are a result of (a) shadows caused by the disparity between the infrared emitter and camera or (b) random missing or spurious values caused by specular or low albedo surfaces.       The raw dataset contains the raw image and accelerometer dumps from the kinect. The RGB and Depth camera sampling rate lies between 20 and 30 FPS (variable over time). While the frames are not synchronized, the timestamps for each of the RGB, depth and accelerometer files are included as part of each filename and can be synchronized to produce a continuous video using the get_synched_frames.m function in the Toolbox.   The dataset is divided into different folders which correspond to each &#8217;scene&#8217; being filmed, such as &#8216;living_room_0012&#8242; or &#8216;office_0014&#8242;. The file hierarchy is structured as follows:   / ../bedroom_0001/ ../bedroom_0001/a-1294886363.011060-3164794231.dump ../bedroom_0001/a-1294886363.016801-3164794231.dump      ... ../bedroom_0001/d-1294886362.665769-3143255701.pgm ../bedroom_0001/d-1294886362.793814-3151264321.pgm      ... ../bedroom_0001/r-1294886362.238178-3118787619.ppm ../bedroom_0001/r-1294886362.814111-3152792506.ppm   Files that begin with the prefix a- are the accelerometer dumps. These dumps are written to disk in binary and can be read with file get_accel_data.mex. Files that begin with the prefix r- and d- are the frames from the RGB and depth cameras, respectively. Since no preprocessing has been performed, the raw depth images must be projected onto the RGB coordinate space into order to align the images.   Toolbox   The matlab toolbox has several useful functions for handling the data.      camera_params.m - Contains the camera parameters for the Kinect used to capture the data.   crop_image.m &#8211; Crops an image to use only the area when the depth signal is projected.   fill_depth_colorization.m &#8211; Fills in the depth using Levin et al's Colorization method.   fill_depth_cross_bf.m - Fills in the depth using a cross-bilateral filter at multiple scales.   get_accel_data.m - Returns the accelerometer parameters at a specific moment in time.   get_instance_masks.m &#8211; Returns a set of binary masks, one for each object instance in an image.   get_rgb_depth_overlay.m &#8211; Returns a visualization of the RGB and Depth alignment.   get_synched_frames.m - Returns a set of synchronized RGB and Depth frames that can be used to produced RGBD videos of each scene.   get_timestamp_from_filename.m &#8211; Returns the timestamp from the raw dataset filenames. This is useful for sampling the RAW video dumps at even intervals in time.   project_depth_map.m &#8211; Projects the Depth map from the Kinect on the RGB image plane.      Raw Dataset Parts     If you don't want to download the entire RAW dataset in a single file, different parts of the dataset can be downloaded individually:          Basements   zip    md5       Bedrooms (6/7)   zip    md5       Home Offices   zip    md5       Misc (2/2)   zip    md5           Bathrooms (1/4)   zip    md5       Bedrooms (7/7)   zip    md5       Kitchens (1/3)   zip    md5       Offices (1/2)   zip    md5           Bathrooms (2/4)   zip    md5       Bookstore (1/3)   zip    md5       Kitchens (2/3)   zip    md5       Offices (2/2)   zip    md5           Bathrooms (3/4)   zip    md5       Bookstore (2/3)   zip    md5       Kitchens (3/3)   zip    md5       Office Kitchens   zip    md5           Bathrooms (4/4)   zip    md5       Bookstore (3/3)   zip    md5       Libraries   zip    md5       Playrooms   zip    md5           Bedrooms (1/7)   zip    md5       Cafe   zip    md5       Living Rooms (1/4)   zip    md5       Reception Rooms   zip    md5           Bedrooms (2/7)   zip    md5       Classrooms   zip    md5       Living Rooms (2/4)   zip    md5       Studies   zip    md5           Bedrooms (3/7)   zip    md5       Dining Rooms (1/2)   zip    md5       Living Rooms (3/4)   zip    md5       Study Rooms   zip    md5           Bedrooms (4/7)   zip    md5       Dining Rooms (2/2)   zip    md5       Living Rooms (4/4)   zip    md5           Bedrooms (5/7)   zip    md5       Furniture Stores   zip    md5       Misc   zip    md5            Correction to Segmentation Results     Due to a bug in the segmentation evaluation, the segmentation results in the paper were about 2% higher across the board:             Features    Weighted Score    Unweighted Score              RGB Only    50.3    44.0          Depth Only    53.7    43.0          RGBD    60.1    47.9          RGBD + Support    60.7    48.8          RGBD + Support + Structure classes    61.1    49.1                                           Pages: Home    Publications    Datasets    Code    About"}]},
{"detail": [{"content": "NYU Depth V2 &laquo; Nathan Silberman                 Nathan Silberman                  NYU Depth Dataset V2     Nathan Silberman ,  Pushmeet Kohli ,  Derek Hoiem ,  Rob Fergus         If you use the dataset, please cite the following work:   Indoor Segmentation and Support Inference from RGBD Images  ECCV 2012  [PDF] [Bib]         Samples of the RGB image, the raw depth image, and the class labels from the dataset.       Overview   The NYU-Depth V2 data set is comprised of video sequences from a variety of indoor scenes as recorded by both the RGB and Depth cameras from the Microsoft Kinect . It features:      1449 densely labeled pairs of aligned RGB and depth images   464 new scenes taken from 3 cities   407,024 new unlabeled frames   Each object is labeled with a class and an instance number (cup1, cup2, cup3, etc)      The dataset has several components:     Labeled: A subset of the video data accompanied by dense multi-class labels. This data has also been preprocessed to fill in missing depth labels.   Raw: The raw rgb, depth and accelerometer data as provided by the Kinect.   Toolbox: Useful functions for manipulating the data and labels.      Downloads        Labeled dataset (~2.8 GB)        Raw dataset, Single File (~428 GB)        Raw dataset, Multi-part (~428 GB)        Toolbox        Labeled Dataset       Output from the RGB camera (left), preprocessed depth (center) and a set of labels (right) for the image.   The labeled dataset is a subset of the Raw Dataset. It is comprised of pairs of RGB and Depth frames that have been synchronized and annotated with dense labels for every image. In addition to the projected depth maps, we have included a set of preprocessed depth maps whose missing values have been filled in using the colorization scheme of Levin et al . Unlike, the Raw dataset, the labeled dataset is provided as a Matlab .mat file with the following variables:     accelData &#8211; Nx4 matrix of accelerometer values indicated when each frame was taken. The columns contain the roll, yaw, pitch and tilt angle of the device.   depths &#8211; HxWxN matrix of in-painted depth maps where H and W are the height and width, respectively and N is the number of images. The values of the depth elements are in meters.   images &#8211; HxWx3xN matrix of RGB images where H and W are the height and width, respectively, and N is the number of images.   instances &#8211; HxWxN matrix of instance maps. Use get_instance_masks.m in the Toolbox to recover masks for each object instance in a scene.   labels &#8211; HxWxN matrix of object label masks where H and W are the height and width, respectively and N is the number of images. The labels range from 1..C where C is the total number of classes. If a pixel&#8217;s label value is 0, then that pixel is &#8216;unlabeled&#8217;.   names &#8211; Cx1 cell array of the english names of each class.   namesToIds &#8211; map from english label names to class IDs (with C key-value pairs)   rawDepths &#8211; HxWxN matrix of raw depth maps where H and W are the height and width, respectively, and N is the number of images. These depth maps capture the depth images after they have been projected onto the RGB image plane but before the missing depth values have been filled in. Additionally, the depth non-linearity from the Kinect device has been removed and the values of each depth image are in meters.   rawDepthFilenames &#8211; Nx1 cell array of the filenames (in the Raw dataset) that were used for each of the depth images in the labeled dataset.   rawRgbFilenames &#8211; Nx1 cell array of the filenames (in the Raw dataset) that were used for each of the RGB images in the labeled dataset.   scenes &#8211; Nx1 cell array of the name of the scene from which each image was taken.   sceneTypes &#8211; Nx1 cell array of the scene type from which each image was taken.     Raw Dataset        Output from the RGB camera (left) and depth camera (right). Missing values in the depth image are a result of (a) shadows caused by the disparity between the infrared emitter and camera or (b) random missing or spurious values caused by specular or low albedo surfaces.       The raw dataset contains the raw image and accelerometer dumps from the kinect. The RGB and Depth camera sampling rate lies between 20 and 30 FPS (variable over time). While the frames are not synchronized, the timestamps for each of the RGB, depth and accelerometer files are included as part of each filename and can be synchronized to produce a continuous video using the get_synched_frames.m function in the Toolbox.   The dataset is divided into different folders which correspond to each &#8217;scene&#8217; being filmed, such as &#8216;living_room_0012&#8242; or &#8216;office_0014&#8242;. The file hierarchy is structured as follows:   / ../bedroom_0001/ ../bedroom_0001/a-1294886363.011060-3164794231.dump ../bedroom_0001/a-1294886363.016801-3164794231.dump      ... ../bedroom_0001/d-1294886362.665769-3143255701.pgm ../bedroom_0001/d-1294886362.793814-3151264321.pgm      ... ../bedroom_0001/r-1294886362.238178-3118787619.ppm ../bedroom_0001/r-1294886362.814111-3152792506.ppm   Files that begin with the prefix a- are the accelerometer dumps. These dumps are written to disk in binary and can be read with file get_accel_data.mex. Files that begin with the prefix r- and d- are the frames from the RGB and depth cameras, respectively. Since no preprocessing has been performed, the raw depth images must be projected onto the RGB coordinate space into order to align the images.   Toolbox   The matlab toolbox has several useful functions for handling the data.      camera_params.m - Contains the camera parameters for the Kinect used to capture the data.   crop_image.m &#8211; Crops an image to use only the area when the depth signal is projected.   fill_depth_colorization.m &#8211; Fills in the depth using Levin et al's Colorization method.   fill_depth_cross_bf.m - Fills in the depth using a cross-bilateral filter at multiple scales.   get_accel_data.m - Returns the accelerometer parameters at a specific moment in time.   get_instance_masks.m &#8211; Returns a set of binary masks, one for each object instance in an image.   get_rgb_depth_overlay.m &#8211; Returns a visualization of the RGB and Depth alignment.   get_synched_frames.m - Returns a set of synchronized RGB and Depth frames that can be used to produced RGBD videos of each scene.   get_timestamp_from_filename.m &#8211; Returns the timestamp from the raw dataset filenames. This is useful for sampling the RAW video dumps at even intervals in time.   project_depth_map.m &#8211; Projects the Depth map from the Kinect on the RGB image plane.      Raw Dataset Parts     If you don't want to download the entire RAW dataset in a single file, different parts of the dataset can be downloaded individually:          Basements   zip    md5       Bedrooms (6/7)   zip    md5       Home Offices   zip    md5       Misc (2/2)   zip    md5           Bathrooms (1/4)   zip    md5       Bedrooms (7/7)   zip    md5       Kitchens (1/3)   zip    md5       Offices (1/2)   zip    md5           Bathrooms (2/4)   zip    md5       Bookstore (1/3)   zip    md5       Kitchens (2/3)   zip    md5       Offices (2/2)   zip    md5           Bathrooms (3/4)   zip    md5       Bookstore (2/3)   zip    md5       Kitchens (3/3)   zip    md5       Office Kitchens   zip    md5           Bathrooms (4/4)   zip    md5       Bookstore (3/3)   zip    md5       Libraries   zip    md5       Playrooms   zip    md5           Bedrooms (1/7)   zip    md5       Cafe   zip    md5       Living Rooms (1/4)   zip    md5       Reception Rooms   zip    md5           Bedrooms (2/7)   zip    md5       Classrooms   zip    md5       Living Rooms (2/4)   zip    md5       Studies   zip    md5           Bedrooms (3/7)   zip    md5       Dining Rooms (1/2)   zip    md5       Living Rooms (3/4)   zip    md5       Study Rooms   zip    md5           Bedrooms (4/7)   zip    md5       Dining Rooms (2/2)   zip    md5       Living Rooms (4/4)   zip    md5           Bedrooms (5/7)   zip    md5       Furniture Stores   zip    md5       Misc   zip    md5            Correction to Segmentation Results     Due to a bug in the segmentation evaluation, the segmentation results in the paper were about 2% higher across the board:             Features    Weighted Score    Unweighted Score              RGB Only    50.3    44.0          Depth Only    53.7    43.0          RGBD    60.1    47.9          RGBD + Support    60.7    48.8          RGBD + Support + Structure classes    61.1    49.1                                           Pages: Home    Publications    Datasets    Code    About"}, {"content": "Data Science at NYU Data Science at NYU                                                                                                                                                                                                             About   What is data science?   Research   Academics       Overview    Programs       News   Contact Us                                                                   Data Science at NYU                                                                                                                                   About   What is data science?   Research   Academics       Overview    Programs       News   Contact Us                                          Data Science at NYU                                                                                                                                                                                      Artificial Intelligence Coming To NYU          IBM Watson Partners with NYU          Learn More                                                                                                                                                        NYU To Collaborate On Multi-Million Dollar Data Science And Big Data Initiative                   Learn More                                                                                                                                                        A University-Wide Initiative          NYU emphasizes data science across schools and research centers.          What's this about?                                                                                                                                                        Center for Data Science          A new research center dedicated to advancing the field of data science.          Learn More                                                                                                                                                         Applied Statistics          Center for the Promotion of Research Involving Innovative Statistical Methodology (PRIISM)          Learn More                                                                                                                                                         Big Data. Big Cities.          Center for Urban Science and Progess          Learn More                                                                                                                                                                What is it         Turning data into insight.                                                               Putting it to Use         From healthcare to business to government.                                                               Process         Exploring the data journey.                                                               The Future         Where will the data revolution take us?                                                                                                                                                     Turning data into insight.   Our networked world is generating a deluge of data that no human, or group of humans, can process fast enough. This data deluge has the potential to transform the way business, government, science and healthcare are carried out. The emerging discipline of data science holds the key to unlocking that potential. It uses automated methods to analyze massive amounts of data and extract knowledge from them. Data science combines aspects of computer science, applied mathematics and statistics.        Big data monitors 12 terabytes of tweets each day to improve product sentiment analysis.     \u201cData science will also revolutionize medicine, education, and other areas that are slated to become \u2018evidence-based.\u2019\u201d \u2014NYU\u2019s Data Science and Statistics Working Group                                                                                                                                        From healthcare to business to government.   Data science is already being put to use in nearly every sphere of modern life. The transportation industry is using it to better predict flight arrival times. Online retailers are using it to better understand consumer habits. Managers are using it to make decisions based on facts rather than instincts. But data science is in its infancy. As it matures, data science holds the promise of creating drugs customized for individual patients, making government run more efficiently and helping our cities be healthier places to live.        By 2010, 28% of the digital universe required some level of data network security.     \u201cRobust, unbiased data are the first step toward addressing our long-term economic needs and key policy priorities.&#8221; \u2014Peter Orszag, Former Director, White House Office of Management and Budget                                                                                                                                          Acquire &amp; Parse   Sensors, medical devices, the Web and smartphones \u2014 to name just a few sources \u2014 capture structured and unstructured data in massive amounts in real-time, all the time.        Filter &amp; Mine   Data scientists use mathematics, statistics, data mining and other automated methods to \u201cclean\u201d data. They also advance the field by developing new automated tools and methodologies.       Analyze &amp; Refine   With an explorer\u2019s desire to uncover what others might not see, data scientists analyze data. Their insights are used in sectors ranging from biology to finance to government.       Interaction   Data scientists excel in presenting complicated findings for experts and non-experts alike. Information visualization, graphic design and human computer interaction all come into play.                                                                                                                                        Where will the data revolution take us?   Data science has already started to revolutionize most areas of intellectual endeavor found at NYU and in the world. We believe this revolution is just beginning. Data science can help us answer not only the great questions and challenges of our time, but also centuries-old questions. Through data science we may improve our understanding of how the brain works, for example. With that understanding we can build intelligent machines capable of advancing life-saving medical research. Data science can help us realize the promises of the digital age.        33% of all data will be stored, or will have passed through the cloud by 2015.     \u201c\u2026Now we really do have essentially free and ubiquitous data. So the complimentary scarce factor is the ability to understand that data and extract value from it.\u201d \u2014Hal Varian, Chief Economist for Google                                                                                                    Unlocking Big Data&#8217;s Potential   From government, social networks and ecommerce sites to sensors, smart meters and mobile networks, data is being collected at an unprecedented speed and scale. Data science can put big data to use.           Average number of \u201clikes\u201d and \u201ccomments\u201d posted on facebook daily.         Percentage of the world\u2019s data that has been produced in the last two years.         Projected volume of  e-commerce \u0003transactions in 2016.                                                                                                                                                  Recent News                         Arthur Spirling To Join NYU This Fall As Joint Faculty in Center for Data Science and Department of Politics Currently the John L. Loeb Associate Professor of the Social Sciences in Harvard University\u2019s Department of Government, Arthur Spirling is a political scientist specializing in political methodology. In addition, he is affiliated with Harvard\u2019s Institute of Quantitative Social Science and is Director of its\u00a0Program on Text Research.\u00a0 Professor Spirling has been honored with Harvard University&#8217;s\u00a0Everett [&hellip;] Read the rest                                                How Spotify is Working on Learning to Improve Playlists Read Story Provided by Center for Data Innovation and Gigaom Read the rest                                                Economics and Big Data Meetup on July 31st: &#8220;Machine Learning: How Should the Art of Decision Making Intersect with Science?&#8221; When: \u00a0Thursday, July 31st at 6:30pm Where: \u00a0NYU Courant, 251 Mercer Street, Room 109, New York, NY 10012 Topic: \u00a0Machine Learning: How Should the Art of Decision Making Intersect with Science? Murli Buluswar, VP and Chief Science Officer at AIG Property/Casualty,\u00a0will be speaking on integrating Behavioral Economics, Data Science and Big Data Platforms and giving [&hellip;] Read the rest                                                When It Comes To Data, Is Bigger Really Better? Foster Provost Says Maybe! Depending On The Characteristics Of The Data It started with a conversation about the value of sparse, fine-grained data versus traditional dense data, then dovetailed into a study to discover which types of data actually lead to better predictive modeling. The researchers were Foster Provost (Professor at NYU) and two Belgian colleagues, Enric Junqu\u00e9 de Fortuny and David Martens. The results, based [&hellip;] Read the rest                                                                                                                                                                                                                                       About     The data science initiative at New York University is a university-wide effort to establish the country\u2019s leading data science training and research facilities at NYU. It was launched to help meet the world\u2019s demand for researchers and professionals skilled in developing and utilizing automated methods of analyzing data. The initiative is especially focused on harnessing the potential power of big data to transform areas ranging from healthcare to business to government. Data science overlaps traditionally strong disciplines at NYU such as mathematics, statistics and computer science. It also stands to impact disciplines in which NYU\u2019s schools and departments are actively engaged, such as economics, law and sociology.                                                                          Where     New York University  Washington Square Campus      Phone     212-998-3401                                                                    Questions or Comments                           Thank you!, We'll be in touch shortly                    Oops!, Looks like something went wrong, ensure you have entered all details correctly!                                                                                                                                                                                                                                                  About   Research   Academics   News                                           Copyright &copy; 2014 |         New York University"}]}]